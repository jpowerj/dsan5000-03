[
  {
    "objectID": "w01/index.html",
    "href": "w01/index.html",
    "title": "Week 1: Welcome to DSAN 5000!",
    "section": "",
    "text": "(Week 1 of DSAN 5000 was a joint session across all individual sections, taught on Zoom.)\n\n\n\n\n\n\nToday’s Links\n\n\n\n\nWeek 1 Lecture Notes\nLab 0 Instructions\nWeek 1 Lecture Recording"
  },
  {
    "objectID": "schedules/w04.html",
    "href": "schedules/w04.html",
    "title": "",
    "section": "",
    "text": "Start\nEnd\nTopic\nRecording\n\n\n\n\nLecture\n3:30pm\n3:40pm\nWeek 03 Recap →\n\n\n\n\n3:40pm\n4:00pm\nQuiz 2.1 \n\n\n\n\n4:00pm\n4:30pm\nData Gathering →\n\n\n\n\n4:30pm\n4:45pm\nWeb Scraping →\n\n\n\n\n4:45pm\n5:00pm\nAPIs →\n\n\n\nBreak!\n5:00pm\n5:10pm\n\n\n\n\nLab\n5:10pm\n5:50pm\nLab Demonstrations →\n\n\n\n\n5:50pm\n6:00pm\nLab Assignment Overview →"
  },
  {
    "objectID": "writeups/columns/index.html",
    "href": "writeups/columns/index.html",
    "title": "Making Multiple Columns",
    "section": "",
    "text": "The following Quarto code:\n\n\n\n\n\n\nQuarto Code Using ::: columns\n\n\n\nHello this is my document\n\n::: columns\n\n::: {.column width=\"50%\"}\n\nHere is column 1\n\n:::\n::: {.column width=\"50%\"}\n\nHere is column 2\n\n:::\n\n:::\n\n\n\nProduces the following rendered output:\n\n\n\n\n\n\nRendered Output Using ::: columns\n\n\n\nHello this is my document\n\n\nHere is column 1\n\nHere is column 2"
  },
  {
    "objectID": "writeups/zotero/index.html",
    "href": "writeups/zotero/index.html",
    "title": "Using Quarto’s Reference Manager with Zotero",
    "section": "",
    "text": "This writeup builds on the more basic approach described in the previous writeup: Using Quarto’s Reference Manager with Google Scholar"
  },
  {
    "objectID": "writeups/zotero/index.html#intro-why-should-i-use-zotero-when-its-more-complicated-than-google-scholar",
    "href": "writeups/zotero/index.html#intro-why-should-i-use-zotero-when-its-more-complicated-than-google-scholar",
    "title": "Using Quarto’s Reference Manager with Zotero",
    "section": "Intro: Why Should I Use Zotero When It’s More Complicated Than Google Scholar?",
    "text": "Intro: Why Should I Use Zotero When It’s More Complicated Than Google Scholar?\nHere, I basically want to convince you to adopt Zotero, with an absolutely crucial extension called Better BibTeX, as your go-to reference manager for the rest of the semester/rest of your academic career, since I can 110% say that it made my life 1000 times easier as I used it more and more throughout the PhD (and, I wish I had started using it sooner!). Not as some sort of awkward self-aggrandizement, but just to show you the power of Zotero, my dissertation ended up having 707 references, and I got literally 5 or 6 emails from Columbia asking me to change the formatting of the references before they would accept it, meaning that without Zotero I would have had to manually update my references\n\\[\n\\underbrace{(707 \\times 6)}_{\\text{Updating in-text}\\atop\\text{citations}} + \\underbrace{(707 \\times 6)}_{\\text{Updating references}\\atop\\text{section}} = 8,484\\text{ times}\n\\]\nwhereas with Zotero it just meant updating a single global setting 6 times.\nHowever, you’ll notice that this is basically the selling point I already gave for Quarto’s references manager (which integrates with Zotero) in the previous writeup. The real selling point of Zotero over manually downloading BibTeX entries using Google Scholar comes from:\n\nThe Zotero Connector, which is a browser extension that lets you click a single button to instantly add any article you’re reading to your Zotero library, and\nThe Better BibTex Extension for Zotero, which truly transforms you into a citation master by automatically syncing your Zotero library with different .bib files across your hard drive.\n\nLong story short, let’s first think about the pipeline of steps you need to perform when using Google Scholar, if you are browsing the web and happen to find an interesting article/book somewhere that you’d like to integrate into your Quarto website:\n\nRemember the name of the article\nOpen up Google Scholar\nSearch the article on Google Scholar\nFind the search result corresponding to the article you are interested in citing (if the article has some generic title like “Postmodernism” or something, it may be many many pages down in the list)\nClick the “Cite” link\nClick the “BibTeX” link\nCopy the BibTeX entry\nManually look through your hard drive for any .bib files that you’d like to update to contain this entry, open them, and paste the entry at the end of the file.\n\nWith Zotero plus these two addons installed, these steps literally become:\n\nClick the Zotero Connector button\n\nAutomatically, immediately after you click this button, Zotero\n\nAdds an entry to your library for this article/book\nScrapes metadata from the page to autofill the various fields: title, authors, date, etc.\nAssigns a citation key to the article/book, based on a template you give it1.\nAutomatically goes out to every .bib file on your computer that you asked it to keep in sync with your library, and adds this entry to the end."
  },
  {
    "objectID": "writeups/zotero/index.html#downloading-zotero-zotero-connector-and-better-bibtex-extension",
    "href": "writeups/zotero/index.html#downloading-zotero-zotero-connector-and-better-bibtex-extension",
    "title": "Using Quarto’s Reference Manager with Zotero",
    "section": "Downloading Zotero, Zotero Connector, and Better BibTeX Extension",
    "text": "Downloading Zotero, Zotero Connector, and Better BibTeX Extension\nSo, if you’re sold on Zotero, you can download the main Zotero program here (there are both Windows and Mac versions).\nOnce you’ve download and installed it, like I mentioned, there is a crucial second piece of the puzzle: kind of like how we had to install both Quarto and the Quarto VSCode Extension to fully Quartify our lives, to fully Zoterify our lives we need both the main Zotero app as well as the Zotero Connector. This is literally a magic button that takes whatever article/book you’re reading, figures out its title/author/year/etc., and adds it to your library.\nThe third and final piece of the puzzle is the Better BibTeX Extension for Zotero. This is the piece that lets you:\n\nSpecify templates for how you would like Zotero to create the citation keys for any article you add via the magic button (see previous footnote), and\nAutomatically update .bib files across your hard drive, to stay in sync with your Zotero library."
  },
  {
    "objectID": "writeups/zotero/index.html#adding-quarto-back-into-the-mix",
    "href": "writeups/zotero/index.html#adding-quarto-back-into-the-mix",
    "title": "Using Quarto’s Reference Manager with Zotero",
    "section": "Adding Quarto Back Into the Mix",
    "text": "Adding Quarto Back Into the Mix\nIf you’ve downloaded Zotero, Zotero Connector, and Better BibTeX, there are really only four remaining steps:\n\nCreate a collection within Zotero, which you’ll use to keep track of all the references that you want to include in a given Quarto project. For example, I have a Zotero collection called “DSAN5000”, where I add (using the magic button) any DSAN5000-related articles. Then,\nRight-click on this collection, select “Export Collection…”, and instead of the standard choices built into Zotero, choose the “Better BibTeX” format. Make sure you check the “Keep Updated” checkbox, and then click “OK”:\n\n\n\nChoose where you’d like it to export the .bib file to (for example, in the same directory as some Quarto file you’re working on, like my_article.qmd), and click “Save”.\nGo into your Quarto document, like my_article.qmd, and add the following line to the YAML metadata block at the top of the file:\n\nbibliography: references.bib\n(if you chose a different name from references.bib when exporting from within Zotero just now, use that name instead)\nThat’s it, you’re done! Better BibTeX keeps track of all the .bib files that you’ve chosen as export locations for this collection, and every time you use the Magic Button to save a book/article to this collection, all of these .bib files will automagically update to contain the new book/article, so that you can immediately cite it in my_article.qmd."
  },
  {
    "objectID": "writeups/zotero/index.html#footnotes",
    "href": "writeups/zotero/index.html#footnotes",
    "title": "Using Quarto’s Reference Manager with Zotero",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nFor example, my template is something like lower(author(1).last)_year_lower(title(1)), which tells Zotero to automatically set the key to be the last name of the first author, then the year, and then the first word of the title, all lowercased.↩︎"
  },
  {
    "objectID": "writeups/lab-1-2-clarifications/index.html",
    "href": "writeups/lab-1-2-clarifications/index.html",
    "title": "Lab 1.2 Clarifications",
    "section": "",
    "text": "Links\n\n\n\nLab 1.2 Link"
  },
  {
    "objectID": "writeups/lab-1-2-clarifications/index.html#component-3-multiple-versions-of-the-about-page",
    "href": "writeups/lab-1-2-clarifications/index.html#component-3-multiple-versions-of-the-about-page",
    "title": "Lab 1.2 Clarifications",
    "section": "Component-3: Multiple Versions of the About Page",
    "text": "Component-3: Multiple Versions of the About Page\nThere is a step in Component-3 which asks you to:\n\nConvert about.qmd to about.ipynb with quarto convert about.qmd.\n\nAfter which (the last bullet in the section) it also asks you to\n\nmodify _quarto.yml accordingly - about.qmd -&gt; about.ipynb\n\nPlease note the following points about these two steps:\n\nMaking sure you have added both href and text data when updating _quarto.yml\n\nWhen you go to modify _quarto.yml, you’ll notice that the Home link is specified using two pieces of information, href and text:\n\n      - href: index.qmd\n        text: Home\n\nHowever, the About link is specified using a single bullet point, just indicating the name of the file:\n\n      - about.qmd\n\nSo, when you go to update _quarto.yml to change about.qmd to about.ipynb, make sure that you include both pieces of information given for the Home link, so that your new link information should now be:\n\n      - href: index.qmd\n        text: Home\n      - href: about.ipynb\n        text: About\n\n\nSpecifying the output format for about.ipynb\n\nAfter running quarto convert about.qmd, you can open the generated about.ipynb file to view the result.\nHowever, you’ll see that the metadata block at the top of the file (the block which starts and ends with ---) only contains the title attribute. That is, the top of the file will look like the following:\n\n---\ntitle: \"About\"\n---\n\nBut, for your website to correctly render this .ipynb file, you’ll need to also add information to this metadata block telling Quarto that you’d like it to output HTML code when it renders about.ipynb for your website.\nTo achieve this, add an additional line within the metadata block (i.e., between the starting --- and the ending ---), after the title: \"About\" line, specifying format: html. If you’ve done this correctly, your metadata block will now look like the following:\n\n---\ntitle: \"About\"\nformat: html\n---\n\nOnce you have added this additional piece of metadata, and saved your changes to the about.ipynb file, you will be halfway to successfully rendering this file as a page within your website. For the second half, see the next point.\n\n\n\nRemoving the about.qmd file\n\nIf you try to quarto render and/or quarto preview the website now, you may find that clicking the “About” link at the top of the page will show just the raw text content of the about.ipynb file, rather than the rendered, nicely-formatted and human-readable version. That is, when you click the “About” link, you may just see a plaintext file with the following contents:\n\n{\n  \"cells\": [\n    {\n      \"cell_type\": \"raw\",\n      \"metadata\": {},\n      \"source\": [\n        \"---\\n\",\n        \"title: \\\"About\\\"\\n\",\n        \"format: html\\n\",\n        \"---\"\n      ]\n    },\n    {\n      \"cell_type\": \"markdown\",\n      \"metadata\": {},\n      \"source\": [\n        \"About this site\"\n      ]\n    }\n  ],\n  \"metadata\": {\n    \"kernelspec\": {\n      \"display_name\": \"Python 3 (ipykernel)\",\n      \"language\": \"python\",\n      \"name\": \"python3\"\n    }\n  },\n  \"nbformat\": 4,\n  \"nbformat_minor\": 4\n}\n\nIf you encounter this issue, you can fix it by resolving the ambiguity that Quarto faces in having both about.qmd and about.ipynb files, and not knowing which one to choose as the file that should be rendered to create the final about.html file, the file that will be placed in the _site directory that quarto render creates.\nTo resolve this ambiguity,\n\nFirst, if you’re paranoid about losing the information in about.qmd, you can back this file up to another folder on your computer.\nThen (or, you can start here if you’re not worried about losing about.qmd), delete the original about.qmd file.\n\nDeleting the original about.qmd file will thus ensure that Quarto has a single about file (in this case, about.ipynb) that it knows is the file you want Quarto to render and show when a user clicks the “About” link."
  },
  {
    "objectID": "writeups/lab-1-2-clarifications/index.html#component-4-and-component-5-lorem-ipsum-text",
    "href": "writeups/lab-1-2-clarifications/index.html#component-4-and-component-5-lorem-ipsum-text",
    "title": "Lab 1.2 Clarifications",
    "section": "Component-4 and Component-5: Lorem Ipsum Text",
    "text": "Component-4 and Component-5: Lorem Ipsum Text\nIn one of the bullets in both the Component-4 section and Component-5 section of the lab, it mentions the following:\n\nNote: Use of ipsum lorem place-holder text is allowed\n\nWhat this means is just: If you would like “filler text” for your index.qmd page, to show what it will look like once it’s filled with content (but without having to write hundreds of words of content yourself), you can use a “Lorem Ipsum text generator” to auto-generate some number of paragraphs (filled with random Latin words), and place this auto-generated text in your index.qmd file.\nTo see why you might want to do this, consider the difference between the following structure with no filler text:\n\n\n\n\n\n\nSection Headers Without Filler Content\n\n\n\nMy Heading\n\nMy Subheading\n\n\nAnother Subheading\n\n\nThird Subheading\n\n\n\nAnd the same structure but “filled out” with paragraphs of randomly-generated text:\n\n\n\n\n\n\nSection Headers With Filler Content\n\n\n\nMy Heading\nLorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Sed cras ornare arcu dui vivamus arcu felis. Dis parturient montes nascetur ridiculus mus. Tincidunt ornare massa eget egestas purus viverra. Porttitor massa id neque aliquam vestibulum morbi. Fringilla phasellus faucibus scelerisque eleifend. Faucibus nisl tincidunt eget nullam non nisi est sit amet. Urna id volutpat lacus laoreet non. Sed pulvinar proin gravida hendrerit lectus a. Sed odio morbi quis commodo odio aenean sed adipiscing. Bibendum at varius vel pharetra vel turpis nunc. Nec dui nunc mattis enim ut tellus elementum sagittis. Nisl rhoncus mattis rhoncus urna neque viverra. Elit at imperdiet dui accumsan.\n\nMy Subheading\nPorta non pulvinar neque laoreet suspendisse interdum consectetur libero id. Laoreet sit amet cursus sit amet dictum sit amet justo. Vitae semper quis lectus nulla at volutpat. Aliquet eget sit amet tellus cras adipiscing enim eu turpis. Tellus elementum sagittis vitae et leo duis ut. Neque vitae tempus quam pellentesque. Cursus eget nunc scelerisque viverra mauris. Morbi leo urna molestie at. Convallis posuere morbi leo urna molestie at elementum. Non consectetur a erat nam. Sagittis nisl rhoncus mattis rhoncus urna neque viverra. Lorem sed risus ultricies tristique.\n\n\nAnother Subheading\nTurpis massa sed elementum tempus egestas. Et netus et malesuada fames ac turpis. Diam maecenas ultricies mi eget mauris pharetra et ultrices neque. Felis imperdiet proin fermentum leo vel orci porta non pulvinar. Vulputate dignissim suspendisse in est. Ultricies mi quis hendrerit dolor magna eget est. Senectus et netus et malesuada fames. Aliquet porttitor lacus luctus accumsan tortor posuere ac. Et ligula ullamcorper malesuada proin libero nunc consequat. Nibh mauris cursus mattis molestie a iaculis. Sit amet commodo nulla facilisi nullam. Mollis nunc sed id semper risus in hendrerit. Sit amet massa vitae tortor condimentum lacinia. Ante in nibh mauris cursus. Aliquam purus sit amet luctus. Tincidunt arcu non sodales neque.\n\n\nThird Subheading\nLorem ipsum dolor sit amet consectetur adipiscing. Tortor pretium viverra suspendisse potenti. Felis eget nunc lobortis mattis aliquam faucibus. Morbi tincidunt ornare massa eget egestas purus viverra. Et netus et malesuada fames ac turpis. Nunc id cursus metus aliquam eleifend. Imperdiet massa tincidunt nunc pulvinar sapien et ligula ullamcorper malesuada. Dignissim diam quis enim lobortis scelerisque. Vel pretium lectus quam id leo in vitae turpis. Venenatis cras sed felis eget velit aliquet. Eu feugiat pretium nibh ipsum. Eu tincidunt tortor aliquam nulla facilisi.\n\n\n\nIf you think this second version looks nicer than the first, and shows more clearly how the headers separate out different pieces of content, you can use this “lorem ipsum” text as filler (until you replace it with your own original writing!)."
  },
  {
    "objectID": "writeups/lab-1-2-clarifications/index.html#component-6",
    "href": "writeups/lab-1-2-clarifications/index.html#component-6",
    "title": "Lab 1.2 Clarifications",
    "section": "Component-6",
    "text": "Component-6\n\nLinking to the Slideshow From Your Main Page\nIn Component-6, the assignment asks you to create a slideshow, with the first two steps being:\n\nCreate a slides subfolder, within simple_quarto_website\nCreate a file within the slides subfolder called slides.ipynb\n\nAnd then it asks you to modify the yaml-format metadata block—this is the block of specially-formatted key-value pairs at the top of the first cell within the slides.ipynb file, that looks like the following (for example):\n---\ntitle: \"My Slideshow\"\n---\nTo specify to Quarto that you’d like it to render this slides.ipynb file specifically as a Reveal.js slideshow, you’ll need to add the following additional key-value pair to this metadata block (which, again, should be at the top of the first cell within slides.ipynb):\nformat: revealjs\nMeaning that, if your original metadata block just had the title, like in the example above, now it will have two pieces of information for Quarto:\n---\ntitle: \"My Slideshow\"\nformat: revealjs\n---\nOnce you’ve specified this format, though, it is still a bit tricky to preview the slideshow (to make sure that modifications you make are actually appearing in the slideshow, for example), since the Quarto extension for VSCode does not provide a nice “Render” button for .ipynb-format files like it does for .qmd-format files.\nSo, you can make your life slightly easier by adding a link to the slideshow from your website’s main navigation bar. To do that, you’ll need to modify your website’s _quarto.yml file, which contains the global settings for the website. If you open this file at this point in the project, it should look something like:\n\n\n_quarto.yml\n\nproject:\n  type: website\n\nwebsite:\n  title: \"simple_quarto_website\"\n  navbar:\n    left:\n      - href: index.qmd\n        text: Home\n      - about.ipynb\n\nformat:\n  html:\n    theme: cosmo\n    toc: true\n\nNotice the portion within the value of website (the indented portions under website:) with the key navbar, and within that value, the key left. Every bullet point underneath this left key will correspond to a link on the top navbar of your website, where the left key indicates that these links will be left-aligned (you could add a new key right:, and some links underneath that key, and those links would be right-aligned on the top navbar).\nSo, to add a link to the slideshow you are creating in slides/slides.ipynb, we’ll need to modify two things in this _quarto.yml file. First, since Quarto will sometimes complain and/or get confused if some links have href and text tags while others do not have this tag, let’s change the link that just contains about.ipynb to have an href and label, like:\n- href: about.ipynb\n  text: About\nThe YAML format requires that elements of a list (like the list of left-aligned links under the left key) line up in terms of indentation, so make sure that the full _quarto.yml file now looks something like:\n\n\n_quarto.yml\n\nproject:\n  type: website\n\nwebsite:\n  title: \"simple_quarto_website\"\n  navbar:\n    left:\n      - href: index.qmd\n        text: Home\n      - href: about.ipynb\n        text: About\n\nformat:\n  html:\n    theme: cosmo\n    toc: true\n\nNow we should be able to add another, third link to this list, allowing us to go directly to the slideshow we’re making in slides/slides.ipynb. To do this, add a new element to the left list by adding another “bullet point” (another - character), then set the href value to be exactly that path (slides/slides.ipynb) and the text value to be “My Slides” (or, any title you’d like). Your _quarto.yml file should now look something like:\n\n\n_quarto.yml\n\nproject:\n  type: website\n\nwebsite:\n  title: \"simple_quarto_website\"\n  navbar:\n    left:\n      - href: index.qmd\n        text: Home\n      - href: about.ipynb\n        text: About\n      - href: slides/slides.ipynb\n        text: Slides\n\nformat:\n  html:\n    theme: cosmo\n    toc: true\n\nand now when you preview your website by running the quarto preview command in the terminal (from within the root directory of your website, which should be named simple_quarto_website), you should see three links in the top navbar: one to “Home”, one to the “About” page, and a third to “Slides”.\nNow, when you actually click the “Slides” link, it may not show anything, or it may show a bunch of non-human-readable raw code (which is actually the .json structure underlying a .ipynb file). This, however, is a separate issue, that you’ll need to tackle: how to get Quarto to know that it should show the Reveal.js presentation as the rendered form of the slides/slides.ipynb file. And that is part of the challenge of the assignment. As a hint, though, you should break it down into steps, to check exactly where this rendering is going wrong (if the slideshow doesn’t render as intended when you click the new “Slides” link):\n\nIf you run the quarto preview command from within the slides folder (rather than the root folder of your website, simple_quarto_website), does it display correctly as a slideshow?\nIs the first cell in your slides.ipynb file in the correct format for containing file metadata? (File metadata can only be entered in “raw” or “markdown” cell types. If the first cell is, for example, a “Python” cell type, Quarto will be unable to read your metadata block, as it will think it’s Python code rather than YAML code).\nDoes the file metadata actually exist in a block at the top of the first cell? As mentioned above, the top of the first cell in your .ipynb file (which should be a “raw” or “markdown” type cell) should look something like\n\n---\ntitle: \"Slides\"\nformat: revealjs\n---\nIf you don’t see text that looks like this at the top of the first cell in your slides.ipynb file, please add it and try to preview the file again (both from the root folder of your website and, for debugging purposes, also from the slides subfolder, as mentioned in step #1 above)"
  },
  {
    "objectID": "writeups/domains-ssh/index.html",
    "href": "writeups/domains-ssh/index.html",
    "title": "Troubleshooting SSH/SCP/rsync on Georgetown Domains",
    "section": "",
    "text": "This tutorial assumes that you have already created a Georgetown Domains account. If you haven’t already done so, or you’re having trouble setting one up, please feel free to email me."
  },
  {
    "objectID": "writeups/domains-ssh/index.html#step-1-creating-a-private-key",
    "href": "writeups/domains-ssh/index.html#step-1-creating-a-private-key",
    "title": "Troubleshooting SSH/SCP/rsync on Georgetown Domains",
    "section": "Step 1: Creating a Private Key",
    "text": "Step 1: Creating a Private Key\nTo remotely access your Georgetown Domains server from your local computer (outside of the method we used before, of accessing the terminal through a web interface), you will first need to create an SSH keypair, which you can think of in two steps:\n\nGeorgetown Domains generates a “keyhole” on your Domains server, a Public Key, which allows your Domains server to be accessed remotely by someone who has the matching private key. Hence, it also creates a\nPrivate Key: a file (in this case, it will be called id_rsa, with no file extension) that you save onto your computer, and you remember where you saved it, that will allow you to access your Georgetown Domains server remotely. There is a third piece of information here, which is the passphrase that will protect your private key from unauthorized usage (this is required by Georgetown, but is optional in general), but we’ll worry about that in a moment.\n\nLet’s generate this keypair step-by-step:\n\nStep 1.1: Opening the “SSH Access” Tool in Georgetown Domains\nOpen your browser and navigate to the Georgetown Domains dashboard. This is the interface that opens if you navigate to https://georgetown.domains/dashboard\nIf you scroll down to the category of tools with the heading “Security”, you will see an icon and a link for “SSH Access”:\n\nClick this link to open the SSH key generation page, and then once this page opens, click the “Manage SSH Keys” button:\n\n\n\nStep 1.2: Generating the Key\nAfter clicking “Manage SSH Keys” and waiting for the next page to load, don’t worry about any of the other options, just click the “+ Generate a New Key” button near the top:\n\nWithin the key-generation form that appears, you don’t need to enter or modify anything except for the Key Password and Reenter Password fields. The way these two fields are phrased is a bit confusing, since you already have a password to access Georgetown services in general (as in, the password that you use to log into Canvas, for example, that requires Two-Factor Authentication): do not enter that password here. This is a new password, really called a passphrase, and all it does it protect your SSH private key from unauthorized usage: if someone manages to steal your id_rsa file, they still won’t be able to access your Georgetown Domains server without knowing this passphrase.\n\nSo, choose a passphrase that is easy to remember and passes Georgetown’s security requirements (it won’t let you submit the form until the passphrase meets those requirements – you can use the “Password Generator” button to auto-generate one if that’s easier), and submit the form by clicking the “Generate Key” button at the bottom.\nIf all went well, you should see a success screen that says “Key Generation Complete!” at the top:\n\nThis screen is also confusing, because it makes it seem like you need to care about the console output that it shows you underneath “Key Generation Complete!”, but in reality you don’t need to worry about it (I excluded it here just in case).\n\n\nStep 1.3: Authorizing This Key to Acess Your Server\nFrom the “Key Generation Complete!” screen, click the “Go Back” link at the bottom of the page to return to the SSH Key Generation panel. You should see the window you saw before, with the “+ Generate a New Key” button at the top, but now below this button you will also see your newly-created pair of keys: the public key just created will now be listed in the “Public Keys” list, and then underneath this the private key just created will be listed in the “Private Keys” list.\nThe first, basic step we need to do is verify with Georgetown Domains that the public key is a valid “keyhole” for remote computers to use to access your Domains server (you’ll notice that it is not authorized by default, so you will see the status “not authorized” within the “Authorization Status” column of the Public Keys list). To activate it, scroll to the Public Keys list and click the “Manage” link (with a wrench icon to the left of it):\n\nThis should bring up a screen where you can straightforwardly click the “Authorize” button to authorize this public key:\n\nAnd, once you click this, you should see a success message like the following:\n\nClick “Go Back” once again to return to the SSH Key Management page.\n\n\nStep 1.4: Downloading the Private Key\nThat is the last time we’ll deal with the public key, the “keyhole” to your server, now that it has been authorized for use. Next, scroll further down to the Private Keys listing, where you should see your id_rsa private key that we generated in Step 1.2:\n\nIn this case, we do want to download this key (as a file) to our local computer, since the ssh (and scp and rsync) command will need to use this key to acess your server. So, click the “View/Download” button (with a disk icon to the left of it). This will bring you to a scary-looking page, that contains your full private key in a big textbox. You don’t need to worry about this, or about the “Convert to PPK” section at the bottom of the page. Just scroll to the button which allows you to download the key file:\n\nIMPORTANT: Make sure that, once this file has downloaded, you move it to a location on your local computer that is secure but also easy to locate, since you will need to know the absolute path to this file, in order to tell the ssh command where to find it. For example, if I copy the key file to my home directory on a Mac, its path might be:\n/Users/jpj/id_rsa\nIf you’re on Windows, and you move it directly onto your C: drive for example, then the path will instead be\nC:\\id_rsa\nSo, just make sure you know this absolute path to the id_rsa file, remembering that it has no file extension: it’s not id_rsa.txt, or id_rsa.pub (that could be what the public key is called), but just id_rsa without extension."
  },
  {
    "objectID": "writeups/domains-ssh/index.html#step-2-using-the-private-key-to-access-your-georgetown-domains-server",
    "href": "writeups/domains-ssh/index.html#step-2-using-the-private-key-to-access-your-georgetown-domains-server",
    "title": "Troubleshooting SSH/SCP/rsync on Georgetown Domains",
    "section": "Step 2: Using the Private Key to Access Your Georgetown Domains Server",
    "text": "Step 2: Using the Private Key to Access Your Georgetown Domains Server\nNow that you have the id_rsa file downloaded, in a location that you can remember the path to (or write down the path to), open up your terminal if you’re on Mac or Git Bash if you’re on Windows. We’ll start by using the ssh command, with our private key (id_rsa) file, to connect to the server.\nThis order is actually somewhat important: we want to start with ssh, not scp or rsync, since the syntax for the scp and rsync commands build upon the syntax for the ssh command. So, I recommend starting with ssh, and working your way towards scp and/or rsync.\nWithin your terminal, we will now “craft” a correct ssh command (you may actually want to have a text editor open, next to your terminal, where you can write out commands to make sure they’re correct before copying-and-pasting them into the terminal). The first part is the name of the command, ssh. So, right now, you should just have the following written in your terminal (don’t press Enter or anything yet, we’re going to press Enter once we finish writing out the command!)\nssh\nNow, we need to give to the ssh command the following information: (a) that we want to use a private key to connect, and (b) the location of our private key, in the form of a path on your local computer’s drive where that key exists.\n\nStep 2.1: Providing ssh the Absolute Path to the Private Key File (id_rsa)\nTo give the information (a), you add the -i flag right after ssh, separated by a space. This tells ssh that you are about to provide a path to a private key file (again, don’t press Enter yet! I will indicate when the command is finished and ready to execute in the terminal):\nssh -i\nNext, we need to provide information (b), the actual path to the private key file, which you should include in double quotes after the -i character (separated by a space). So, for example, if I had moved my private key to /Users/jpj/id_rsa, then the command at this point would look like:\nssh -i \"/Users/jpj/id_rsa\"\nIf I was on Windows, and I had saved it directly in the root of my C: directory, then the command would instead look like:\nssh -i \"C:\\id_rsa\"\n\n\nStep 2.2: Providing Your Georgetown Domains Username and Domain\nNow, there are two final pieces of information that we need to provide to the ssh command: (a) our username on our Georgetown Domains server, and (b) the domain that the Georgetown Domains system has allocated for us. To find both pieces of information, you can navigate back to the Georgetown Domains Dashboard main page: https://georgetown.domains/dashboard, and look for this info box near the top of the page, on the right side of the page:\n\nThe only information that we need is in the first two rows of this info box: in my case, this shows me that:\n\nMy username is jpjgeorg, and\nMy domain is jpj.georgetown.domains\n\nThese are exactly the two pieces of information we were looking for! Moving back to the terminal, we can now complete the ssh command by entering this information in the form username@domain, separated from the end of the private key file path by a space. Using my information, the command is now\nssh -i \"/path/to/private/key/file\" jpjgeorg@jpj.georgetown.domains\nKeep in mind that this username@domain portion may look strange to you, if your username and your domain are similar/identical. For example, it may have assigned you the username dsanstudent, and the domain dsanstudent.georgetown.domains: in this case, you need to make sure to include both pieces of information: dsanstudent@dsanstudent.georgetown.domains. Long story short, the Georgetown Domains system creates a custom server just for you, and makes you the only user on this custom server, so that information gets repeated in this address: the dsanstudent.georgetown.domains server is created, with one user called dsanstudent.\n\n\nStep 2.3: Running the SSH Command\nNow that we understand this, we can run our command:\nssh -i \"/path/to/private/key/file\" username@domain\nIf you don’t see a scary all-caps error that looks like the following:\n@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n@         WARNING: UNPROTECTED PRIVATE KEY FILE!          @\n@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\nPermissions for 'id_rsa' are too open.\nIt is required that your private key files are NOT accessible by others.\nThis private key will be ignored.\nLoad key \"id_rsa\": bad permissions\nubuntu@192.168.0.1: Permission denied (publickey).\nthen you can jump to the next step. However, some students are getting this error. If you see this, you can fix it by doing the following:\n\n\n\n\n\n\nFixing the INCORRECT PRIVATE KEY PERMISSIONS Error\n\n\n\nIf you see an error that looks like the above, with WARNING: UNPROTECTED PRIVATE KEY FILE! all in caps, this means that when you downloaded you private key from the browser (Chrome, Firefox, etc.), it set the permissions on this file to be the “standard” permissions for any downloaded file, which is not what we want for the private key file, since this is an extremely important file that we want to keep secured. So, we’ll have the change the permissions on this file to be as secure as possible while still allowing us to use it in the terminal.\nSo, open up a new terminal window. Using the cd command (along with pwd to see what your current working directory is), navigate to the location where your id_rsa file is stored. Once you have arrived at that path (you can tell by running ls and seeing if id_rsa is one of the files listed in the directory), you can use the following command to change the permissions on the id_rsa file to the required settings for ssh access:\nchmod 600 id_rsa\nThis tells your computer to change the permissions of the id_rsa file to the permissions code 600, which corresponds to the case where you (the owner) have read and write permissions, but anyone else has no permissions (no read, no write, and no execute) on this file. One you’ve done this, to make sure it worked, you can check the permissions on the id_rsa file specifically by running\nls -lah id_rsa\nThis should print out a detailed listing of information on the id_rsa file, and should look like the following if the permissions were set correctly:\n\n-rw-------@ 1 jpj  staff   1.7K Jun  9 23:40 id_rsa\n(Your computer should show your own username rather than jpj, and some usergroup besides staff, but the permissions string should look similar to the string all the way on the left of the above output: the -rw-------@ portion)\n\n\n\n\nStep 2.4: Entering the SSH Key Passphrase\nIf you did not encounter this WARNING: UNPROTECTED PRIVATE KEY FILE error, or if you encountered it but fixed it by changing the permissions on the id_rsa file and re-running the previous command (the ssh command), then the terminal should now be asking you for a passphrase for your SSH private key. In my case, this looks like:\n\njpj@GSAS-AL-06LVHQQ domains % ssh -i \"id_rsa\" jpjgeorg@jpj.georgetown.domains\nEnter passphrase for key 'id_rsa': \nAnd then (on Mac) it shows a tiny key icon after the : character (on Windows it should just show an empty black or white box). This is asking you to enter the SSH key passphrase that you created in step 1.2 above, not your general Georgetown account password that you use to access other Georgetown services like Canvas! So, start typing (or paste) that SSH key passphrase into the terminal.\nSome students have gotten worried at this point, because they notice that the cursor does not move as they type their passwords: this is the expected behavior, even though it feels weird to type and not see any feedback on the screen! It is a feature on Linux, which ensures that even if people are watching your screen, they cannot see how long your password is (it turns out that cracking passwords becomes much much easier, in many cases, if you know in advance how long the person’s password is).\nSo, you won’t see any feedback on the screen, but once you’ve typed or pasted your SSH secret key passphrase, press enter.\n\n\nStep 2.5: Checking That The Connection Was Successful\nIf the location of the private key file was successfully provided to the ssh command via the string after the -i flag, and if the private key passphrase was entered correctly, then it should successfully connect to your Georgetown Domains server. If you have indeed successfully connected, your terminal prompt (the portion of the terminal where you type new commands) will suddenly change. Whereas before it may have looked like\n\njpj@GSAS-AL-06LVHQQ ~ %\nNow it should look like\n\n[jpjgeorg@gtown3 ~]$ \nIf you’ve never logged in before, it may show some additional info above this prompt, but if you have logged in before, it will also show the following above the prompt:\n\nLast login: Sun Sep 10 21:47:30 2023 from 216.15.21.131\n[jpjgeorg@gtown3 ~]$\nYou have now successfully connected to your Georgetown Domains server! There is one remaining step, which will help us to move from just connecting to the server via ssh to transferring files to/from the server via scp or rsync.\n\n\nStep 2.6: Finding Your public_html Path\nOnce you have successfully connected to the server, you should also browse the directory structure to see how it works. In particular, as a first step, try just running\n\npwd\nThis should just show the full, absolute path to your home directory. In my case, the output was\n\n/home/jpjgeorg\nNext, run\n\nls\nIt should show a bunch of files and folders (probably not the same as the following output), but you should at least see a public_html subfolder:\n\naccess-logs    dsan-conference-posters  mail           public_ftp   tmp     www\ncomposer.json  etc                      _metadata.yml  public_html  var\ncomposer.lock  logs                     perl5          ssl          vendor\nThis public_html subfolder, within your home folder, is where your Georgetown Domains web server will look for and serve files when people type your domain (like dsanstudent.georgetown.domains) into their browser’s address bar.\nSo, let’s move into this public_html directory, by entering and executing\ncd public_html\nIf we now check our working directory, by entering and executing\npwd\nYou should now see something that looks like the following:\n/home/jpjgeorg/public_html\nYou should take a screenshot of this path, or write it down, or remember it some other way. Because, this is the remote path (the path on the remote server) that you’ll want to copy your local files to, when we ask you e.g. to copy your _site directory to your Georgetown Domains server."
  },
  {
    "objectID": "writeups/domains-ssh/index.html#step-2.7-exiting-the-ssh-session-and-returning-to-your-local-computer",
    "href": "writeups/domains-ssh/index.html#step-2.7-exiting-the-ssh-session-and-returning-to-your-local-computer",
    "title": "Troubleshooting SSH/SCP/rsync on Georgetown Domains",
    "section": "Step 2.7: Exiting the SSH Session and Returning to Your Local Computer",
    "text": "Step 2.7: Exiting the SSH Session and Returning to Your Local Computer\nNow that you know how to connect to a remote server using ssh, you’ll have to be a bit more vigilant about noticing which computer you’re working on when you are typing and running commands in the terminal. As mentioned above, if you see a terminal prompt that looks like the following\n[jpjgeorg@gtown3 ~]$\nThen this terminal is probably connected to your Georgetown Domains server, meaning that any commands you enter will be run on the Georgetown Domains server. If instead you see a terminal prompt that looks like\njpj@GSAS-AL-06LVHQQ ~ %\nThat means you are safely back on your local machine, so that the commands you enter will be run locally, on the processor of your laptop. Since we just finished an SSH session, however, we are probably still logged in to the Georgetown Domains server. So, to exit this session and return back to executing commands on your local machine, just enter and execute the exit command:\nexit\nIf successful, it should show output like the following:\nlogout\nConnection to jpj.georgetown.domains closed."
  },
  {
    "objectID": "writeups/domains-ssh/index.html#step-3-moving-from-ssh-to-scp",
    "href": "writeups/domains-ssh/index.html#step-3-moving-from-ssh-to-scp",
    "title": "Troubleshooting SSH/SCP/rsync on Georgetown Domains",
    "section": "Step 3: Moving from ssh to scp",
    "text": "Step 3: Moving from ssh to scp\nNow that you know how to provide the necessary information and connect to your Georgetown Domains server using the ssh command, we’ll move to the scp command. Basically, while the ssh command lets you connect to and “look around” inside your server, the scp command allows you to transfer files to and from your server. The information you need to provide, and the syntax, are very similar, so we’re done with the hardest parts!\n\nStep 3.1: Providing the Absolute Path to Your Private Key File (id_rsa)\nJust like the ssh command, you can provide a -i flag (short for “identity file”), followed by the path to your ssh private key file, as information for the scp command, as follows (again, don’t press Enter until we’re finished writing out the full command, in a later step):\nscp -i \"/path/to/your/file\"\nIn my case, since my file is located within the /Users/jpj/ directory on my hard drive, I start the scp command with\nscp -i \"/Users/jpj/id_rsa\"\n\n\nStep 3.2: Providing the Path (Absolute or Relative) to the Local File You’d Like to Copy\nNext, I need to give scp the path to the file that I’d like to copy to my Georgetown Domains server. Note that here we’re starting with file copying rather than folder copying, which I strongly recommend so that you can check whether the syntax of your scp command is correct before trying to copy a ton of files. Specifically, I recommend just making a test file called hello.txt, and seeing if you can successfully use scp to copy this file from your local drive to your Georgetown Domains server. To create a fake file like this very quickly, you can open a new terminal window and run the following commands:\ntouch hello.txt\necho \"Hello World\" &gt;&gt; hello.txt\nWherever you run these two commands, there will now be a hello.txt file which contains the text Hello World. Now, let’s try to copy this file to our Georgetown Domains server—specifically, the public_html directory within our Georgetown Domains server. To get there, we need to finish up the remaining parts of our scp command. Add in the path to the file on your local drive that you want to copy to the remote server as the next argument to scp, like:\nscp -i \"/path/to/your/key/file\" \"hello.txt\"\nIn this case, since I created hello.txt in the same directory that I am now executing the scp command from, I don’t need to provide an absolute path (like /Users/jpj/hello.txt). In general, though, if you’re trying to copy a file from somewhere in your computer that is not your current working directory, you need to include an absolute or relative path to that file here.\n\n\nStep 3.3: Providing the username@domain String\nNext, we include the username@domain information in the exact same way we included it in the ssh command, making our command look like this:\nscp -i \"/path/to/your/key/file\" \"hello.txt\" jpjgeorg@jpj.georgetown.domains\n\n\nStep 3.4: Providing the Remote Path Where We’d Like Our File(s) To Be Copied To\nThere is one last piece of information we need to provide: the path on the remote server where we would like to copy hello.txt to! In this case, we wrote it down in a previous step: it was /home/jpjgeorg/public_html. So, we enter this as the last piece of information in our scp command, but in a bit of a strange-looking way: we add a colon (:) to the end of the username@domain string, and then provide the desired remote path after this colon character. So, in this case, to transfer to the /home/jpjgeorg/public_html directory, we finish writing out the command as follows:\nscp -i \"/path/to/your/key/file\" \"hello.txt\" jpjgeorg@jpj.georgetown.domains:/home/jpjgeorg/public_html\n\n\nStep 3.5: Executing the Command\nFinally, we can press Enter and execute the command! If it worked successfully, you may see a summary of the information: that it has transferred a single file, with size of only a few bytes, called hello.txt. Now let’s check to make sure the copy actually worked\n\n\nStep 3.6: Making Sure The Copy Was Successful\nThere are two ways you could check that this copy worked. The first, and safer way, would be to ssh into our remote server again, use cd to navigate to the public_html directory, and then execute ls and check that hello.txt is one of the listed files.\nHowever, since public_html is a special directory, that is publicly-available, we could also check that hello.txt transferred correctly by opening our browser and typing our domain followed by /hello.txt. So, in my case for example, you or I or anyone else could open https://jpj.georgetown.domains/hello.txt, and check to see that it indeed shows the content Hello world!. If your domain also shows this, when you go to (for example) dsanstudent.georgetown.domains, then you know that the transfer was a success!\n\n\nStep 3.7: Copying Entire Folders Instead Of Just One File\nThere is only one more change you need to make to the scp command from above (the command which copied a file), to make it copy an entire folder rather than just one file. If you add an additional -r flag to the very beginning of your ssh command, before the -i flag, you are instructing ssh that it should copy the local path that you provide recursively. Meaning: if you now provide a path to a folder as the argument to ssh immediately after the path to your private key file (rather than a path to a file like we entered before), ssh will now recursiviely copy the folder and all of its contents to the specified remote directory.\nSo for example, if I had a folder called mysite within my home directory /home/jpj/ on my local drive, then I could modify the previous scp command as follows, to copy this folder to my Georgetown Domains server:\nscp -r -i \"/path/to/my/key/file\" \"/Users/jpj/mysite\" jpjgeorg@jpj.georgetown.domains:/home/jpjgeorg/public_html\nThis command, once executed, should now show a series of messages, indicating the progress/completion of each file within the mysite folder, as it copies them one-by-one into the /home/jpjgeorg/public_html/mysite folder on my remote machine.\nOnce this command completes, you can again check that the copy was successful in one of two ways: either (a) by using ssh to log into the server, then using cd and ls to move to the public_html folder and check its contents, or (b) opening your browser and checking (in my case) https://jpj.georgetown.domains/mysite.\nAs one final thing to notice: unlike in the case of ssh, we don’t need to use exit to leave an scp “session”. That is because, scp immediately exits from the remote server once the files have been copied. So, immediately after the scp command completes, you are still on your local computer, and commands that you enter and execute are still run locally (when in doubt, look for the terminal prompt! If it looks like [jpjgeorg@gtown3 ~]$, that means you still need to exit from the Georgetown Domains server back to your local machine.)"
  },
  {
    "objectID": "w02/index.html",
    "href": "w02/index.html",
    "title": "Week 2: Data Science Fundamentals and Workflow",
    "section": "",
    "text": "Today’s Links\n\n\n\n\nWeek 2 Lecture Notes\nLab 1 Home\n\n\n\nToday’s Planned Schedule:\n\n\n\n\n\n\n\n\n\n\n\n\nStart\nEnd\nTopic\nSlides\nNotes\n\n\n\n\nLecture\n3:30pm\n3:35pm\n[About Me]\n\n\n\n\n\n3:35pm\n3:50pm\nComputer Fundamentals\n\n\n\n\n\n3:50pm\n4:05pm\nCoding Fundamentals\n\n\n\n\n\n4:05pm\n4:20pm\nHTML and CSS\n\n\n\n\n\n4:20pm\n4:35pm\nObjects and Classes\n\n\n\n\n\n4:35pm\n4:50pm\nQuiz 1.1 (Canvas)\n\n\n\n\nBreak!\n4:50pm\n5:00pm\n\n\n\n\n\nLab\n5:00pm\n5:25pm\nLab 1 Part I: Coding Demonstration\n\n\n\n\n\n5:25pm\n5:50pm\nLab 1 Part II: HTML/CSS Demonstration\n\n\n\n\n\n5:50pm\n6:00pm\nLab 1 Assignment Overview"
  },
  {
    "objectID": "w04/slides.html#git-commands",
    "href": "w04/slides.html#git-commands",
    "title": "Week 4: Data Gathering and APIs",
    "section": "Git Commands",
    "text": "Git Commands\n\n\n\n\n\n\n\nCommand\nWhat It Does\n\n\n\n\ngit clone\nDownloads a repo from the web to our local computer\n\n\ngit init\nCreates a new, blank Git repository on our local computer (configuration/change-tracking stored in .git subfolder)\n\n\ngit add\nStages a file(s): Git will now track changes in this file(s)\n\n\ngit reset\nUndoes a git add\n\n\ngit status\nShows currently staged files and their status (created, modified, deleted)\n\n\ngit commit -m \"message\"\n“Saves” the current version of all staged files, ready to be pushed to a backup dir or remote server like GitHub\n\n\ngit push\nTransmits local commits to remote server\n\n\ngit pull\nDownloads commits from remote server to local computer\n\n\ngit merge\nMerges remote versions of files with local versions"
  },
  {
    "objectID": "w04/slides.html#reproducible-docsliterate-programming",
    "href": "w04/slides.html#reproducible-docsliterate-programming",
    "title": "Week 4: Data Gathering and APIs",
    "section": "Reproducible Docs/Literate Programming",
    "text": "Reproducible Docs/Literate Programming\n\n1980s: \\(\\LaTeX\\) for \\(\\widehat{\\mathcal{T}}\\)ypesetting \\(\\sqrt{math}^2\\)\n1990s: Python and R as powerful scripting languages (no compilation required)\n2000s/2010s: Interactive Python via Jupyter, fancy IDE for R called RStudio\n2020s: Quarto (using pandoc under the hood) enables use of markdown for formatting, \\(\\LaTeX\\) for math, and both Python and R in same document, with choice of output formats (HTML, presentations, Word docs, …)"
  },
  {
    "objectID": "w04/slides.html#preexisting-data-sources",
    "href": "w04/slides.html#preexisting-data-sources",
    "title": "Week 4: Data Gathering and APIs",
    "section": "Preexisting Data Sources",
    "text": "Preexisting Data Sources\n\nDepending on your field, or the type of data you’re looking for, there may be a “standard” data source! For example:\nEconomics:\n\nUS data: FRED\nGlobal data: World Bank Open Data, OECD Data, etc.\n\nPolitical Science:\n\nICPSR\n\nNetwork Science:\n\nStanford SNAP: Large Network Dataset Collection"
  },
  {
    "objectID": "w04/slides.html#web-scraping",
    "href": "w04/slides.html#web-scraping",
    "title": "Week 4: Data Gathering and APIs",
    "section": "Web Scraping",
    "text": "Web Scraping\n\nFun fact: you can view a webpage’s HTML source code by right-clicking on the page and selecting “View Source”\n\nOn older websites, this means we can just request page and parse the returned HTML\n\nLess fun fact: modern web frameworks (React, Next.js) generate pages dynamically using JS, meaning that what you see on the page will not be visible in the HTML source\n\nData scraping still possible for these sites! Using browser automation tools like Selenium"
  },
  {
    "objectID": "w04/slides.html#scraping-difficulty",
    "href": "w04/slides.html#scraping-difficulty",
    "title": "Week 4: Data Gathering and APIs",
    "section": "Scraping Difficulty",
    "text": "Scraping Difficulty\n\n\n\n\n\n\n\n\n\n\n\n\n\nHow is data loaded?\nSolution\nExample\n\n\n\n\n😊\nEasy\nData in HTML source\n“View Source”\n\n\n\n😐\nMedium\nData loaded dynamically via API\n“View Source”, find API call, scrape programmatically\n\n\n\n😳\nHard\nData loaded dynamically [internally] via web framework\nUse Selenium"
  },
  {
    "objectID": "w04/slides.html#data-structures-foundations",
    "href": "w04/slides.html#data-structures-foundations",
    "title": "Week 4: Data Gathering and APIs",
    "section": "Data Structures: Foundations",
    "text": "Data Structures: Foundations\n\nCould be (is) a whole class\nCould be (is) a whole class just for one type of data (geographic/spatial)\nFor this class: some foundational principles that should let you figure out fancier data structures you encounter"
  },
  {
    "objectID": "w04/slides.html#opening-datasets-with-your-terminator-glasses-on",
    "href": "w04/slides.html#opening-datasets-with-your-terminator-glasses-on",
    "title": "Week 4: Data Gathering and APIs",
    "section": "Opening Datasets With Your Terminator Glasses On",
    "text": "Opening Datasets With Your Terminator Glasses On\n\n\n\n\nWhat does a row represent?\nWhat does a column represent?\nWhat does a value in a cell represent?\nAre there unique identifiers for the objects you care about?\n\n\n\n\n\n\nFigure 1: What you should see when you look at a new dataset"
  },
  {
    "objectID": "w04/slides.html#from-raw-data-to-clean-data",
    "href": "w04/slides.html#from-raw-data-to-clean-data",
    "title": "Week 4: Data Gathering and APIs",
    "section": "From Raw Data to Clean Data",
    "text": "From Raw Data to Clean Data"
  },
  {
    "objectID": "w04/slides.html#data-structures-simple-rightarrow-complex",
    "href": "w04/slides.html#data-structures-simple-rightarrow-complex",
    "title": "Week 4: Data Gathering and APIs",
    "section": "Data Structures: Simple \\(\\rightarrow\\) Complex",
    "text": "Data Structures: Simple \\(\\rightarrow\\) Complex\n\n\n\n\n\n\n\nid\nname\nemail\n\n\n\n\n0\nK. Desbrow\nkd9@dailymail.com\n\n\n1\nD. Minall\ndminall1@wired.com\n\n\n2\nC. Knight\nck2@microsoft.com\n\n\n3\nM. McCaffrey\nmccaf4@nhs.uk\n\n\n\nFigure 2: Record Data\n\n\n\n\n\n\n\nyear\nmonth\npoints\n\n\n\n\n2023\nJan\n65\n\n\n2023\nFeb\n\n\n\n2023\nMar\n42\n\n\n2023\nApr\n11\n\n\n\nFigure 3: Time-Series Data\n\n\n\n\n\n\n\n\n\nid\ndate\nrating\nnum_rides\n\n\n\n\n0\n2023-01\n0.75\n45\n\n\n0\n2023-02\n0.89\n63\n\n\n0\n2023-03\n0.97\n7\n\n\n1\n2023-06\n0.07\n10\n\n\n\nFigure 4: Panel Data\n\n\n\n\n\n\n\nSource\nTarget\nWeight\n\n\n\n\nIGF2\nIGF1R\n1\n\n\nIGF1R\nTP53\n2\n\n\nTP53\nEGFR\n0.5\n\n\n\nFigure 5: Network Data\n\n\n\n\n\n\nFake data via Mockaroo and Random.org. Protein-protein interaction network from Agrawal, Zitnik, and Leskovec (2018)"
  },
  {
    "objectID": "w04/slides.html#tabular-data-vs.-relational-data",
    "href": "w04/slides.html#tabular-data-vs.-relational-data",
    "title": "Week 4: Data Gathering and APIs",
    "section": "Tabular Data vs. Relational Data",
    "text": "Tabular Data vs. Relational Data\n\nAll of the datasets on the previous slide are tabular\nDatabases like SQLite, MySQL, require us to think about relationships within and between tabular datasets\nImagine you’re creating the backend for a social network. How would you record users and friendships? Your intuition may be record data:\n\n\n\n\n\n\n\n\n\n\n\nid\nname\nfriends\n\n\n\n\n1\nPurna\n[2,3,4]\n\n\n2\nJeff\n[1,3,4,5,6]\n\n\n3\nJames\n[1,2,4,6]\n\n\n4\nNakul\n[1,2,3]\n\n\n5\nDr. Fauci\n[2,6]\n\n\n6\nPitbull\n[2,5]\n\n\n\nFigure 6: Our first attempt at a data structure for our social network app’s backend\n\n\n\nLong story short…\n\nThis doesn’t scale\nExtremely inefficient to find whether two users are friends\nRedundant information: Have to store friendship between A and B in both A’s row and B’s row"
  },
  {
    "objectID": "w04/slides.html#a-better-approach",
    "href": "w04/slides.html#a-better-approach",
    "title": "Week 4: Data Gathering and APIs",
    "section": "A Better Approach",
    "text": "A Better Approach\n\nMove the friendship data into its own table!\nThis table now represents relational data, (user table still corresponds to records):\n\n\n\n\n\n\n\n\n\n\n\nuser_id\nname\n\n\n\n\n1\nPurna\n\n\n2\nJeff\n\n\n3\nJames\n\n\n4\nNakul\n\n\n5\nDr. Fauci\n\n\n6\nPitbull\n\n\n\nFigure 7: The user table in our relational structure\n\n\n\n\n\n\n\n\n\n\nid\nfriend_1\nfriend_2\nid\nfriend_1\nfriend_2\n\n\n\n\n1\n1\n2\n6\n2\n5\n\n\n2\n1\n3\n7\n2\n6\n\n\n3\n1\n4\n8\n3\n4\n\n\n4\n2\n3\n9\n3\n6\n\n\n5\n2\n4\n10\n5\n6\n\n\n\nFigure 8: The friendships table in our relational structure\n\n\n\n\n\nMay seem weird in terms of human readability, but think in terms of memory/computational efficiency: (a) Scalable, (b) Easy to find if two users are friends (via sorting/searching algorithms), (c) No redundant info"
  },
  {
    "objectID": "w04/slides.html#dbs-relational-or-otherwise",
    "href": "w04/slides.html#dbs-relational-or-otherwise",
    "title": "Week 4: Data Gathering and APIs",
    "section": "DBs: Relational or Otherwise",
    "text": "DBs: Relational or Otherwise\n\nFor rest of lecture we zoom in on cases where data comes as individual files\nBut on top of the relational format from previous slide, there are also non-relational database formats, like the document-based format used by e.g. MongoDB1\nIn either case, data is spread over many files, so that to obtain a single dataset we use queries.\n\n\n\n\n\n\n\n\n\n\n\n\nG\n\n  \n\nfile\n\n File (.csv/.json/etc.)   \n\nload\n\n read_csv()   \n\nfile-&gt;load\n\n    \n\ndataset\n\n Dataset   \n\nload-&gt;dataset\n\n   \n\n\n\n\n\nFigure 9: Statically datasets (as individual files on disk)\n\n\n\n\n\n\n\n\n\n\n\nG\n\n \n\ncluster_00\n\n Database   \n\ntab1\n\n Table 1   \n\nquery\n\n Query   \n\ntab1-&gt;query\n\n    \n\ntab2\n\n Table 2   \n\ntab2-&gt;query\n\n    \n\ntabdots\n\n …   \n\ntabdots-&gt;query\n\n    \n\ntabN\n\n Table N   \n\ntabN-&gt;query\n\n    \n\ndataset\n\n Dataset   \n\nquery-&gt;dataset\n\n   \n\n\n\n\n\nFigure 10: Datasets formed dynamically via database queries\n\n\n\n\nFor (much) more on this topic, see this page from Prisma, a high-level “wrapper” that auto-syncs your DB structure with a TypeScript schema, so your code knows exactly “what’s inside” a variable whose content was retrieved from the DB…"
  },
  {
    "objectID": "w04/slides.html#data-formats",
    "href": "w04/slides.html#data-formats",
    "title": "Week 4: Data Gathering and APIs",
    "section": "Data Formats",
    "text": "Data Formats\n\nThe most common formats, for most fields:\n\n.csv: Comma-Separated Values\n.tsv: Tab-Separated Values\n.json: JavaScript Object Notation\n.xls/.xlsx: Excel format\n.dta: Stata format"
  },
  {
    "objectID": "w04/slides.html#csv-.tsv",
    "href": "w04/slides.html#csv-.tsv",
    "title": "Week 4: Data Gathering and APIs",
    "section": ".csv / .tsv",
    "text": ".csv / .tsv\n\n\n👍\n\n\nmy_data.csv\n\nindex,var_1,var_2,var_3\nA,val_A1,val_A2,val_A3\nB,val_B1,val_B2,val_B3\nC,val_C1,val_C2,val_C3\nD,val_D1,val_D2,val_D3\n\n\n(👎)\n\n\nmy_data.tsv\n\nindex var_1 var_2 var_3\nA val_A1  val_A2  val_A3\nB val_B1  val_B2  val_B3\nC val_C1  val_C2  val_C3\nD val_D1  val_D2  val_D3\n\n\n\n→\n\n\n\n\n\n\n\n\n\n\n\n\n\nPython: pd.read_csv() (from Pandas library)\nR: read_csv() (from readr library)"
  },
  {
    "objectID": "w04/slides.html#json",
    "href": "w04/slides.html#json",
    "title": "Week 4: Data Gathering and APIs",
    "section": ".json",
    "text": ".json\n\n\n\ncourses.json\n\n{\n  \"dsan5000\": {\n    \"title\": \"Data Science and Analytics\",\n    \"credits\": 3,\n    \"lectures\": [\n      \"Intro\",\n      \"Tools and Workflow\"\n    ]\n  },\n  \"dsan5100\": {\n    \"title\": \"Probabilistic Modeling and Statistical Computing\",\n    \"credits\": 3,\n    \"lectures\": [\n      \"Intro\",\n      \"Conditional Probability\"\n    ]\n  }\n}\n\n\n\nPython: json (built-in library, import json)\nR: jsonlite (install.packages(jsonlite))\nHelpful validator (for when .json file won’t load)"
  },
  {
    "objectID": "w04/slides.html#other-formats",
    "href": "w04/slides.html#other-formats",
    "title": "Week 4: Data Gathering and APIs",
    "section": "Other Formats",
    "text": "Other Formats\n\n.xls/.xlsx: Requires special libraries in Python/R\n\nPython: openpyxl\nR: readxl (part of tidyverse)\n\n.dta: Stata format, but can be read/written to in Python/R\n\nPython: Pandas has built-in pd.read_stata() and pd.to_stata()\nR: read_dta() from Haven library (part of tidyverse)"
  },
  {
    "objectID": "w04/slides.html#scraping-html-with-requests-and-beautifulsoup",
    "href": "w04/slides.html#scraping-html-with-requests-and-beautifulsoup",
    "title": "Week 4: Data Gathering and APIs",
    "section": "Scraping HTML with requests and BeautifulSoup",
    "text": "Scraping HTML with requests and BeautifulSoup\nrequests Documentation | BeautifulSoup Documentation\n\n\nCode\n# Get HTML\nimport requests\n# Perform request\nresponse = requests.get(\"https://en.wikipedia.org/wiki/Data_science\")\n# Parse HTML\nfrom bs4 import BeautifulSoup\nsoup = BeautifulSoup(response.text, 'html.parser')\nall_headers = soup.find_all(\"h2\")\nsection_headers = [h.find(\"span\", {'class': 'mw-headline'}).text for h in all_headers[1:]]\nsection_headers\n\n\n['Foundations', 'Etymology', 'Data Science and Data Analysis', 'History', 'See also', 'References']"
  },
  {
    "objectID": "w04/slides.html#navigating-html-with-beautifulsoup",
    "href": "w04/slides.html#navigating-html-with-beautifulsoup",
    "title": "Week 4: Data Gathering and APIs",
    "section": "Navigating HTML with BeautifulSoup",
    "text": "Navigating HTML with BeautifulSoup\n\nLet’s focus on this line from the previous slide:\n\nall_headers = soup.find_all(\"h2\")\n\nfind_all() is the key function for scraping!\nIf the HTML has a repeating structure (like rows in a table), find_all() can instantly parse this structure into a Python list."
  },
  {
    "objectID": "w04/slides.html#the-power-of-find_all",
    "href": "w04/slides.html#the-power-of-find_all",
    "title": "Week 4: Data Gathering and APIs",
    "section": "The Power of find_all()",
    "text": "The Power of find_all()\n\n\n\n\n\n\ndata_page.html\n\n&lt;div class=\"all-the-data\"&gt;\n    &lt;h4&gt;First Dataset&lt;/h4&gt;\n    &lt;div class=\"data-1\"&gt;\n        &lt;div class=\"dataval\"&gt;1&lt;/div&gt;\n        &lt;div class=\"dataval\"&gt;2&lt;/div&gt;\n        &lt;div class=\"dataval\"&gt;3&lt;/div&gt;\n    &lt;/div&gt;\n    &lt;h4&gt;Second Dataset&lt;/h4&gt;\n    &lt;div class=\"data-2\"&gt;\n        &lt;ul&gt;\n            &lt;li&gt;4.0&lt;/li&gt;\n            &lt;li&gt;5.5&lt;/li&gt;\n            &lt;li&gt;6.7&lt;/li&gt;\n        &lt;/ul&gt;\n    &lt;/div&gt;\n&lt;/div&gt;\n\nFigure 11: Data in page elements (&lt;div&gt;, &lt;li&gt;)\n\n\n\n\n\n    First Dataset\n    \n        1\n        2\n        3\n    \n    Second Dataset\n        \n            4.0\n            5.5\n            6.7\n        \n\nFigure 12: The code from Figure 11, rendered by your browser\n\n\n\n\n\n\n\nfrom bs4 import BeautifulSoup\nsoup = BeautifulSoup(page_html, 'html.parser')\nds1_elt = soup.find(\"div\", class_='data-1')\nds1 = [e.text for e in ds1_elt.find_all(\"div\")]\nds2_elt = soup.find(\"div\", {'class': 'data-2'})\nds2 = [e.text for e in ds2_elt.find_all(\"li\")]\n\nFigure 13: The BeautifulSoup code used to parse the HTML\n\n\n\n\n\nprint(f\"dataset-1: {ds1}\\ndataset-2: {ds2}\")\n\ndataset-1: ['1', '2', '3']\ndataset-2: ['4.0', '5.5', '6.7']\n\n\nFigure 14: Contents of the Python variables holding the parsed data"
  },
  {
    "objectID": "w04/slides.html#parsing-html-tables",
    "href": "w04/slides.html#parsing-html-tables",
    "title": "Week 4: Data Gathering and APIs",
    "section": "Parsing HTML Tables",
    "text": "Parsing HTML Tables\n\n\n\n\n\n\ntable_data.html\n\n&lt;table&gt;\n&lt;thead&gt;\n    &lt;tr&gt;\n        &lt;th&gt;X1&lt;/th&gt;&lt;th&gt;X2&lt;/th&gt;&lt;th&gt;X3&lt;/th&gt;\n    &lt;/tr&gt;\n&lt;/thead&gt;\n&lt;tbody&gt;\n    &lt;tr&gt;\n        &lt;td&gt;1&lt;/td&gt;&lt;td&gt;3&lt;/td&gt;&lt;td&gt;5&lt;/td&gt;\n    &lt;/tr&gt;\n    &lt;tr&gt;\n        &lt;td&gt;2&lt;/td&gt;&lt;td&gt;4&lt;/td&gt;&lt;td&gt;6&lt;/td&gt;\n    &lt;/tr&gt;\n&lt;/tbody&gt;\n&lt;/table&gt;\n\nFigure 15: Data in HTML table format\n\n\n\n\n\n\n\nX1\nX2\nX3\n\n\n\n\n1\n3\n5\n\n\n2\n4\n6\n\n\n\nFigure 16: The HTML table code, as rendered by your browser\n\n\n\n\n\n\n\nfrom bs4 import BeautifulSoup\nsoup = BeautifulSoup(table_html, 'html.parser')\nthead = soup.find(\"thead\")\nheaders = [e.text for e in thead.find_all(\"th\")]\ntbody = soup.find(\"tbody\")\nrows = tbody.find_all(\"tr\")\ndata = [[e.text for e in r.find_all(\"td\")]\n            for r in rows]\n\nFigure 17: The BeautifulSoup code used to parse the table HTML\n\n\n\n\n\nprint(f\"headers: {headers}\\ndata: {data}\")\n\nheaders: ['X1', 'X2', 'X3']\ndata: [['1', '3', '5'], ['2', '4', '6']]\n\n\nFigure 18: Contents of the Python variables holding the parsed data"
  },
  {
    "objectID": "w04/slides.html#what-does-an-api-do",
    "href": "w04/slides.html#what-does-an-api-do",
    "title": "Week 4: Data Gathering and APIs",
    "section": "What Does an API Do?",
    "text": "What Does an API Do?\nExposes endpoints for use by developers, without requiring them to know the nuts and bolts of your pipeline/service:\n\n\n\n\n\n\n\n\nExample\nEndpoint\nNot Exposed\n\n\n\n\nElectrical outlet\nSocket\nInternal wiring\n\n\nWater fountain\nAerator\nWater pump\n\n\nCar\nPedals, Steering wheel, etc.\nEngine\n\n\n\n\nWhen I’m teaching programming to students in refugee camps who may have never used a computer before, I try to use the idea of “robots”: a program is a robot trained to sit there and wait for inputs, then process them in some way and spit out some output. APIs really capture this notion, honestly."
  },
  {
    "objectID": "w04/slides.html#example-math-api",
    "href": "w04/slides.html#example-math-api",
    "title": "Week 4: Data Gathering and APIs",
    "section": "Example: Math API",
    "text": "Example: Math API\n\nBase URL: https://newton.vercel.app/api/v2/\nThe endpoint: factor\nThe argument: \"x^2 - 1\"\nThe request: https://newton.vercel.app/api/v2/factor/x^2-1\n\n\n\nCode\nimport requests\nresponse = requests.get(\"https://newton.vercel.app/api/v2/factor/x^2-1\")\nprint(response.json())\n\n\n{'operation': 'factor', 'expression': 'x^2-1', 'result': '(x - 1) (x + 1)'}"
  },
  {
    "objectID": "w04/slides.html#math-api-endpoints",
    "href": "w04/slides.html#math-api-endpoints",
    "title": "Week 4: Data Gathering and APIs",
    "section": "Math API Endpoints",
    "text": "Math API Endpoints\n\n\n\nOperation\nAPI Endpoint\nResult\n\n\n\n\nSimplify\n/simplify/2^2+2(2)\n8\n\n\nFactor\n/factor/x^2 + 2x\nx (x + 2)\n\n\nDerive\n/derive/x^2+2x\n2 x + 2\n\n\nIntegrate\n/integrate/x^2+2x\n1/3 x^3 + x^2 + C\n\n\nFind 0’s\n/zeroes/x^2+2x\n[-2, 0]\n\n\nFind Tangent\n/tangent/2|x^3\n12 x + -16\n\n\nArea Under Curve\n/area/2:4|x^3\n60\n\n\nCosine\n/cos/pi\n-1\n\n\nSine\n/sin/0\n0\n\n\nTangent\n/tan/0\n0"
  },
  {
    "objectID": "w04/slides.html#authentication",
    "href": "w04/slides.html#authentication",
    "title": "Week 4: Data Gathering and APIs",
    "section": "Authentication",
    "text": "Authentication\n\nUnlike the math API, most APIs do not allow requests to be made by anonymous requesters, and require authentication.\nFor example, you can access public GitHub repos anonymously, but to access private GitHub repos using GitHub’s API, you’ll need to authenticate that you are in fact the one making the request"
  },
  {
    "objectID": "w04/slides.html#authentication-via-pygithub",
    "href": "w04/slides.html#authentication-via-pygithub",
    "title": "Week 4: Data Gathering and APIs",
    "section": "Authentication via PyGithub",
    "text": "Authentication via PyGithub\n\n\n\nPyGithub Installation\n\n\nInstall using the following terminal/shell command [Documentation]\npip install PyGithub\n\n\n\nPyGithub can handle authentication for you. Example: this private repo in my account does not show up unless the request is authenticated (via a Personal Access Token)1:\n\n\n\n\n\n\nimport github\ng = github.Github()\ntry:\n    g.get_repo(\"jpowerj/private-repo-test\")\nexcept Exception as e:\n    print(e)\n\n404 {\"message\": \"Not Found\", \"documentation_url\": \"https://docs.github.com/rest/repos/repos#get-a-repository\"}\n\n\n\nFigure 19: Using the GitHub API without authentication\n\n\n\n\n\n\n# Load the access token securely\nimport dotenv\ndotenv.load_dotenv(\"../.env\", override=True)\nimport os\nmy_access_token = os.getenv('GITHUB_TOKEN')\nimport github\n# Use the access token to make an API request\nauth = github.Auth.Token(my_access_token)\ng = github.Github(auth=auth)\ng.get_user().get_repo(\"private-repo-test\")\n\nRepository(full_name=\"jpowerj/private-repo-test\")\n\n\n\nFigure 20: Using the GitHub API with authentication\n\n\n\n\nYour code should 🚨never🚨 contain authentication info, especially when using GitHub. In this case, I created an OS environment variable called GITHUB_TOKEN containing my Personal Access Token, which I then loaded using os.getenv() and provided to PyGithub."
  },
  {
    "objectID": "w04/slides.html#wikipedia-api",
    "href": "w04/slides.html#wikipedia-api",
    "title": "Week 4: Data Gathering and APIs",
    "section": "Wikipedia API",
    "text": "Wikipedia API\nWikipedia API Demo Link"
  },
  {
    "objectID": "w04/slides.html#google-scholar-api",
    "href": "w04/slides.html#google-scholar-api",
    "title": "Week 4: Data Gathering and APIs",
    "section": "Google Scholar API",
    "text": "Google Scholar API\nGoogle Scholar API Demo Link"
  },
  {
    "objectID": "w04/slides.html#news-api",
    "href": "w04/slides.html#news-api",
    "title": "Week 4: Data Gathering and APIs",
    "section": "News API",
    "text": "News API\nNews API Lab Demo Link"
  },
  {
    "objectID": "w04/slides.html#lab-assignment-overview",
    "href": "w04/slides.html#lab-assignment-overview",
    "title": "Week 4: Data Gathering and APIs",
    "section": "Lab Assignment Overview",
    "text": "Lab Assignment Overview\nLab 2.1"
  },
  {
    "objectID": "w04/slides.html#references",
    "href": "w04/slides.html#references",
    "title": "Week 4: Data Gathering and APIs",
    "section": "References",
    "text": "References\n\n\nAgrawal, Monica, Marinka Zitnik, and Jure Leskovec. 2018. “Large-Scale Analysis of Disease Pathways in the Human Interactome.” In PACIFIC SYMPOSIUM on BIOCOMPUTING 2018: Proceedings of the Pacific Symposium, 111–22. World Scientific.\n\n\nMenczer, Filippo, Santo Fortunato, and Clayton A. Davis. 2020. A First Course in Network Science. Cambridge University Press."
  },
  {
    "objectID": "w04/slides.html#scraping-html-with-httr2-and-xml2",
    "href": "w04/slides.html#scraping-html-with-httr2-and-xml2",
    "title": "Week 4: Data Gathering and APIs",
    "section": "Scraping HTML with httr2 and xml2",
    "text": "Scraping HTML with httr2 and xml2\nhttr2 Documentation | xml2 Documentation\n\n\nCode\n# Get HTML\nlibrary(httr2)\nrequest_obj &lt;- request(\"https://en.wikipedia.org/wiki/Data_science\")\nresponse_obj &lt;- req_perform(request_obj)\n# Parse HTML\nlibrary(xml2)\nhtml_obj &lt;- response_obj %&gt;% resp_body_html()\nhtml_obj %&gt;% xml_find_all('//h2//span[@class=\"mw-headline\"]')\n\n\n{xml_nodeset (6)}\n[1] &lt;span class=\"mw-headline\" id=\"Foundations\"&gt;Foundations&lt;/span&gt;\n[2] &lt;span class=\"mw-headline\" id=\"Etymology\"&gt;Etymology&lt;/span&gt;\n[3] &lt;span class=\"mw-headline\" id=\"Data_Science_and_Data_Analysis\"&gt;Data Scienc ...\n[4] &lt;span class=\"mw-headline\" id=\"History\"&gt;History&lt;/span&gt;\n[5] &lt;span class=\"mw-headline\" id=\"See_also\"&gt;See also&lt;/span&gt;\n[6] &lt;span class=\"mw-headline\" id=\"References\"&gt;References&lt;/span&gt;\n\n\n\n\nNote: httr2 is a re-written version of the original httr package, which is now deprecated. You’ll still see lots of code using httr, however, so it’s good to know how both versions work. Click here for a helpful vignette on the original httr library."
  },
  {
    "objectID": "w04/slides.html#navigating-html-with-xpath",
    "href": "w04/slides.html#navigating-html-with-xpath",
    "title": "Week 4: Data Gathering and APIs",
    "section": "Navigating HTML with XPath",
    "text": "Navigating HTML with XPath\nXPath Cheatsheet\n\nNotice the last line on the previous slide:\n\nhtml_obj %&gt;% xml_find_all('//h2//span[@class=\"mw-headline\"]')\n\nThe string passed to xml_find_all() is an XPath selector\n\n\n\nXPath selectors are used by many different libraries, including Selenium (which we’ll look at very soon) and jQuery (a standard extension to plain JavaScript allowing easy searching/manipulation of the DOM), so it’s good to learn it now!"
  },
  {
    "objectID": "w04/slides.html#xpath-i-selecting-elements",
    "href": "w04/slides.html#xpath-i-selecting-elements",
    "title": "Week 4: Data Gathering and APIs",
    "section": "XPath I: Selecting Elements",
    "text": "XPath I: Selecting Elements\n\n\nmypage.html\n\n&lt;div class=\"container\"&gt;\n  &lt;h1&gt;Header&lt;/h1&gt;\n  &lt;p id=\"page-content\"&gt;Content&lt;/p&gt;\n  &lt;img class=\"footer-image m-5\" src=\"footer.png\"&gt;\n&lt;/div&gt;\n\n\n'//div' matches all elements &lt;div&gt; in the document:\n&lt;div class=\"container\"&gt;\n  &lt;h1&gt;Header&lt;/h1&gt;\n  &lt;p id=\"page-content\"&gt;Content&lt;/p&gt;\n  &lt;img class=\"footer-image m-5\" src=\"footer.png\"&gt;\n&lt;/div&gt;\n'//div//img' matches &lt;img&gt; elements which are children of &lt;div&gt; elements:\n&lt;img class=\"footer-image m-5\" src=\"footer.png\"&gt;"
  },
  {
    "objectID": "w04/slides.html#xpath-ii-filtering-by-attributes",
    "href": "w04/slides.html#xpath-ii-filtering-by-attributes",
    "title": "Week 4: Data Gathering and APIs",
    "section": "XPath II: Filtering by Attributes",
    "text": "XPath II: Filtering by Attributes\n\n\nmypage.html\n\n&lt;div class=\"container\"&gt;\n  &lt;h1&gt;Header&lt;/h1&gt;\n  &lt;p id=\"page-content\"&gt;Content&lt;/p&gt;\n  &lt;img class=\"footer-image m-5\" src=\"footer.png\"&gt;\n&lt;/div&gt;\n\n\n'//p[id=\"page-content\"]' matches all &lt;p&gt; elements with id page-content1:\n&lt;p id=\"page-content\"&gt;Content&lt;/p&gt;\nMatching classes is a bit trickier:\n'//img[contains(concat(\" \", normalize-space(@class), \" \"), \" footer-image \")]'\nmatches all &lt;img&gt; elements with page-content as one of their classes2\n&lt;img class=\"footer-image m-5\" src=\"footer.png\"&gt;\n\nIn HTML, ids are required to be unique to particular elements (and elements cannot have more than one id), meaning that this should only return a single element, for valid HTML code (not followed by all webpages!). Also note the double-quotes after id=, which are required in XPath.Your intuition may be to just use '//img[@class=\"footer-image\"]'. Sadly, however, this will match only elements with footer-image as their only class. i.e., it will match &lt;img class=\"footer-image\"&gt; but not &lt;img class=\"footer-image another-class\"&gt;. This will usually fail, since most elements on modern webpages have several classes. For example, if the site is using Bootstrap, &lt;p class=\"p-5 m-3\"&gt;&lt;/p&gt; creates a paragraph element with a padding of 5 pixels and a margin of 3 pixels."
  },
  {
    "objectID": "w04/slides.html#example-math-api-1",
    "href": "w04/slides.html#example-math-api-1",
    "title": "Week 4: Data Gathering and APIs",
    "section": "Example: Math API",
    "text": "Example: Math API\n\nBase URL: https://newton.vercel.app/api/v2/\nThe endpoint: factor\nThe argument: \"x^2 - 1\"\nThe request: https://newton.vercel.app/api/v2/factor/x^2-1\n\n\n\nCode\nlibrary(httr2)\nrequest_obj &lt;- request(\"https://newton.vercel.app/api/v2/factor/x^2-1\")\nresponse_obj &lt;- req_perform(request_obj)\nwriteLines(response_obj %&gt;% resp_body_string())\n\n\n{\"operation\":\"factor\",\"expression\":\"x^2-1\",\"result\":\"(x - 1) (x + 1)\"}"
  },
  {
    "objectID": "w04/slides.html#authentication-1",
    "href": "w04/slides.html#authentication-1",
    "title": "Week 4: Data Gathering and APIs",
    "section": "Authentication",
    "text": "Authentication\n\nMost APIs don’t allow requests to be made by anonymous requesters, and require authentication.\nFor example, to access private GitHub repos using GitHub’s API, you’ll need to authenticate that you are in fact the one making the request"
  },
  {
    "objectID": "w04/slides.html#authentication-via-gh",
    "href": "w04/slides.html#authentication-via-gh",
    "title": "Week 4: Data Gathering and APIs",
    "section": "Authentication via GH",
    "text": "Authentication via GH\n\nThe GH library for R can handle this authentication process for you. For example, this private repo in my account does not show up if requested anonymously, but does show up when requested using GH with a Personal Access Token1:\n\n\n\nCode\nlibrary(gh)\nresult &lt;- gh(\"GET /repos/jpowerj/private-repo-test\")\nwriteLines(paste0(result$name, \": \",result$description))\n\n\nprivate-repo-test: Private repo example for DSAN5000\n\n\n \n\n\n\n\nYour code should never contain authentication info, especially when using GitHub. In this case, I created an OS environment variable called GITHUB_TOKEN containing my Personal Access Token, which GH then uses to make authenticated requests."
  },
  {
    "objectID": "w04/index.html",
    "href": "w04/index.html",
    "title": "Week 4: Data Gathering and APIs",
    "section": "",
    "text": "Open slides in new window →"
  },
  {
    "objectID": "w04/index.html#git-commands",
    "href": "w04/index.html#git-commands",
    "title": "Week 4: Data Gathering and APIs",
    "section": "Git Commands",
    "text": "Git Commands\n\n\n\n\n\n\n\nCommand\nWhat It Does\n\n\n\n\ngit clone\nDownloads a repo from the web to our local computer\n\n\ngit init\nCreates a new, blank Git repository on our local computer (configuration/change-tracking stored in .git subfolder)\n\n\ngit add\nStages a file(s): Git will now track changes in this file(s)\n\n\ngit reset\nUndoes a git add\n\n\ngit status\nShows currently staged files and their status (created, modified, deleted)\n\n\ngit commit -m \"message\"\n“Saves” the current version of all staged files, ready to be pushed to a backup dir or remote server like GitHub\n\n\ngit push\nTransmits local commits to remote server\n\n\ngit pull\nDownloads commits from remote server to local computer\n\n\ngit merge\nMerges remote versions of files with local versions"
  },
  {
    "objectID": "w04/index.html#reproducible-docsliterate-programming",
    "href": "w04/index.html#reproducible-docsliterate-programming",
    "title": "Week 4: Data Gathering and APIs",
    "section": "Reproducible Docs/Literate Programming",
    "text": "Reproducible Docs/Literate Programming\n\n1980s: \\(\\LaTeX\\) for \\(\\widehat{\\mathcal{T}}\\)ypesetting \\(\\sqrt{math}^2\\)\n1990s: Python and R as powerful scripting languages (no compilation required)\n2000s/2010s: Interactive Python via Jupyter, fancy IDE for R called RStudio\n2020s: Quarto (using pandoc under the hood) enables use of markdown for formatting, \\(\\LaTeX\\) for math, and both Python and R in same document, with choice of output formats (HTML, presentations, Word docs, …)"
  },
  {
    "objectID": "w04/index.html#preexisting-data-sources",
    "href": "w04/index.html#preexisting-data-sources",
    "title": "Week 4: Data Gathering and APIs",
    "section": "Preexisting Data Sources",
    "text": "Preexisting Data Sources\n\nDepending on your field, or the type of data you’re looking for, there may be a “standard” data source! For example:\nEconomics:\n\nUS data: FRED\nGlobal data: World Bank Open Data, OECD Data, etc.\n\nPolitical Science:\n\nICPSR\n\nNetwork Science:\n\nStanford SNAP: Large Network Dataset Collection"
  },
  {
    "objectID": "w04/index.html#web-scraping",
    "href": "w04/index.html#web-scraping",
    "title": "Week 4: Data Gathering and APIs",
    "section": "Web Scraping",
    "text": "Web Scraping\n\nFun fact: you can view a webpage’s HTML source code by right-clicking on the page and selecting “View Source”\n\nOn older websites, this means we can just request page and parse the returned HTML\n\nLess fun fact: modern web frameworks (React, Next.js) generate pages dynamically using JS, meaning that what you see on the page will not be visible in the HTML source\n\nData scraping still possible for these sites! Using browser automation tools like Selenium"
  },
  {
    "objectID": "w04/index.html#scraping-difficulty",
    "href": "w04/index.html#scraping-difficulty",
    "title": "Week 4: Data Gathering and APIs",
    "section": "Scraping Difficulty",
    "text": "Scraping Difficulty\n\n\n\n\n\n\n\n\n\n\n\n\n\nHow is data loaded?\nSolution\nExample\n\n\n\n\n😊\nEasy\nData in HTML source\n“View Source”\n\n\n\n😐\nMedium\nData loaded dynamically via API\n“View Source”, find API call, scrape programmatically\n\n\n\n😳\nHard\nData loaded dynamically [internally] via web framework\nUse Selenium"
  },
  {
    "objectID": "w04/index.html#data-structures-foundations",
    "href": "w04/index.html#data-structures-foundations",
    "title": "Week 4: Data Gathering and APIs",
    "section": "Data Structures: Foundations",
    "text": "Data Structures: Foundations\n\nCould be (is) a whole class\nCould be (is) a whole class just for one type of data (geographic/spatial)\nFor this class: some foundational principles that should let you figure out fancier data structures you encounter"
  },
  {
    "objectID": "w04/index.html#opening-datasets-with-your-terminator-glasses-on",
    "href": "w04/index.html#opening-datasets-with-your-terminator-glasses-on",
    "title": "Week 4: Data Gathering and APIs",
    "section": "Opening Datasets With Your Terminator Glasses On",
    "text": "Opening Datasets With Your Terminator Glasses On\n\n\n\n\nWhat does a row represent?\nWhat does a column represent?\nWhat does a value in a cell represent?\nAre there unique identifiers for the objects you care about?\n\n\n\n\n\n\nFigure 1: What you should see when you look at a new dataset"
  },
  {
    "objectID": "w04/index.html#from-raw-data-to-clean-data",
    "href": "w04/index.html#from-raw-data-to-clean-data",
    "title": "Week 4: Data Gathering and APIs",
    "section": "From Raw Data to Clean Data",
    "text": "From Raw Data to Clean Data"
  },
  {
    "objectID": "w04/index.html#data-structures-simple-rightarrow-complex",
    "href": "w04/index.html#data-structures-simple-rightarrow-complex",
    "title": "Week 4: Data Gathering and APIs",
    "section": "Data Structures: Simple \\(\\rightarrow\\) Complex",
    "text": "Data Structures: Simple \\(\\rightarrow\\) Complex\n\n\n\n\n\n\n\nid\nname\nemail\n\n\n\n\n0\nK. Desbrow\nkd9@dailymail.com\n\n\n1\nD. Minall\ndminall1@wired.com\n\n\n2\nC. Knight\nck2@microsoft.com\n\n\n3\nM. McCaffrey\nmccaf4@nhs.uk\n\n\n\nFigure 2: Record Data\n\n\n\n\n\n\n\nyear\nmonth\npoints\n\n\n\n\n2023\nJan\n65\n\n\n2023\nFeb\n\n\n\n2023\nMar\n42\n\n\n2023\nApr\n11\n\n\n\nFigure 3: Time-Series Data\n\n\n\n\n\n\n\n\n\nid\ndate\nrating\nnum_rides\n\n\n\n\n0\n2023-01\n0.75\n45\n\n\n0\n2023-02\n0.89\n63\n\n\n0\n2023-03\n0.97\n7\n\n\n1\n2023-06\n0.07\n10\n\n\n\nFigure 4: Panel Data\n\n\n\n\n\n\n\nSource\nTarget\nWeight\n\n\n\n\nIGF2\nIGF1R\n1\n\n\nIGF1R\nTP53\n2\n\n\nTP53\nEGFR\n0.5\n\n\n\nFigure 5: Network Data\n\n\n\n\n\n\nFake data via Mockaroo and Random.org. Protein-protein interaction network from Agrawal, Zitnik, and Leskovec (2018)"
  },
  {
    "objectID": "w04/index.html#tabular-data-vs.-relational-data",
    "href": "w04/index.html#tabular-data-vs.-relational-data",
    "title": "Week 4: Data Gathering and APIs",
    "section": "Tabular Data vs. Relational Data",
    "text": "Tabular Data vs. Relational Data\n\nAll of the datasets on the previous slide are tabular\nDatabases like SQLite, MySQL, require us to think about relationships within and between tabular datasets\nImagine you’re creating the backend for a social network. How would you record users and friendships? Your intuition may be record data:\n\n\n\n\n\n\n\n\n\n\n\nid\nname\nfriends\n\n\n\n\n1\nPurna\n[2,3,4]\n\n\n2\nJeff\n[1,3,4,5,6]\n\n\n3\nJames\n[1,2,4,6]\n\n\n4\nNakul\n[1,2,3]\n\n\n5\nDr. Fauci\n[2,6]\n\n\n6\nPitbull\n[2,5]\n\n\n\nFigure 6: Our first attempt at a data structure for our social network app’s backend\n\n\n\nLong story short…\n\nThis doesn’t scale\nExtremely inefficient to find whether two users are friends\nRedundant information: Have to store friendship between A and B in both A’s row and B’s row"
  },
  {
    "objectID": "w04/index.html#a-better-approach",
    "href": "w04/index.html#a-better-approach",
    "title": "Week 4: Data Gathering and APIs",
    "section": "A Better Approach",
    "text": "A Better Approach\n\nMove the friendship data into its own table!\nThis table now represents relational data, (user table still corresponds to records):\n\n\n\n\n\n\n\n\n\n\n\nuser_id\nname\n\n\n\n\n1\nPurna\n\n\n2\nJeff\n\n\n3\nJames\n\n\n4\nNakul\n\n\n5\nDr. Fauci\n\n\n6\nPitbull\n\n\n\nFigure 7: The user table in our relational structure\n\n\n\n\n\n\n\n\n\n\nid\nfriend_1\nfriend_2\nid\nfriend_1\nfriend_2\n\n\n\n\n1\n1\n2\n6\n2\n5\n\n\n2\n1\n3\n7\n2\n6\n\n\n3\n1\n4\n8\n3\n4\n\n\n4\n2\n3\n9\n3\n6\n\n\n5\n2\n4\n10\n5\n6\n\n\n\nFigure 8: The friendships table in our relational structure\n\n\n\n\n\nMay seem weird in terms of human readability, but think in terms of memory/computational efficiency: (a) Scalable, (b) Easy to find if two users are friends (via sorting/searching algorithms), (c) No redundant info"
  },
  {
    "objectID": "w04/index.html#dbs-relational-or-otherwise",
    "href": "w04/index.html#dbs-relational-or-otherwise",
    "title": "Week 4: Data Gathering and APIs",
    "section": "DBs: Relational or Otherwise",
    "text": "DBs: Relational or Otherwise\n\nFor rest of lecture we zoom in on cases where data comes as individual files\nBut on top of the relational format from previous slide, there are also non-relational database formats, like the document-based format used by e.g. MongoDB1\nIn either case, data is spread over many files, so that to obtain a single dataset we use queries.\n\n\n\n\n\n\n\n\n\n\n\n\nG\n\n  \n\nfile\n\n File (.csv/.json/etc.)   \n\nload\n\n read_csv()   \n\nfile-&gt;load\n\n    \n\ndataset\n\n Dataset   \n\nload-&gt;dataset\n\n   \n\n\n\n\n\nFigure 9: Statically datasets (as individual files on disk)\n\n\n\n\n\n\n\n\n\n\n\nG\n\n \n\ncluster_00\n\n Database   \n\ntab1\n\n Table 1   \n\nquery\n\n Query   \n\ntab1-&gt;query\n\n    \n\ntab2\n\n Table 2   \n\ntab2-&gt;query\n\n    \n\ntabdots\n\n …   \n\ntabdots-&gt;query\n\n    \n\ntabN\n\n Table N   \n\ntabN-&gt;query\n\n    \n\ndataset\n\n Dataset   \n\nquery-&gt;dataset\n\n   \n\n\n\n\n\nFigure 10: Datasets formed dynamically via database queries"
  },
  {
    "objectID": "w04/index.html#data-formats",
    "href": "w04/index.html#data-formats",
    "title": "Week 4: Data Gathering and APIs",
    "section": "Data Formats",
    "text": "Data Formats\n\nThe most common formats, for most fields:\n\n.csv: Comma-Separated Values\n.tsv: Tab-Separated Values\n.json: JavaScript Object Notation\n.xls/.xlsx: Excel format\n.dta: Stata format"
  },
  {
    "objectID": "w04/index.html#csv-.tsv",
    "href": "w04/index.html#csv-.tsv",
    "title": "Week 4: Data Gathering and APIs",
    "section": ".csv / .tsv",
    "text": ".csv / .tsv\n\n\n👍\n\n\nmy_data.csv\n\nindex,var_1,var_2,var_3\nA,val_A1,val_A2,val_A3\nB,val_B1,val_B2,val_B3\nC,val_C1,val_C2,val_C3\nD,val_D1,val_D2,val_D3\n\n\n(👎)\n\n\nmy_data.tsv\n\nindex var_1 var_2 var_3\nA val_A1  val_A2  val_A3\nB val_B1  val_B2  val_B3\nC val_C1  val_C2  val_C3\nD val_D1  val_D2  val_D3\n\n\n\n→\n\n\n\nsource(\"../_globals.r\")\nlibrary(readr)\ndata &lt;- read_csv(\"assets/my_data.csv\")\n\nRows: 3 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): index, var_1, var_2, var_3\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ndisp(data)\n\n\n\n\n\n# | index | var_1 | var_2 | var_3 |\n# | - | - | - | - |\n# | A | val_A1 | val_A2 | val_A3 |\n# | B | val_B1 | val_B2 | val_B3 |\n# | C | val_C1 | val_C2 | val_C3 |\n# | D | val_D1 | val_D2 | val_D3 | \n\n\n\n\n\nPython: pd.read_csv() (from Pandas library)\nR: read_csv() (from readr library)"
  },
  {
    "objectID": "w04/index.html#json",
    "href": "w04/index.html#json",
    "title": "Week 4: Data Gathering and APIs",
    "section": ".json",
    "text": ".json\n\n\n\ncourses.json\n\n{\n  \"dsan5000\": {\n    \"title\": \"Data Science and Analytics\",\n    \"credits\": 3,\n    \"lectures\": [\n      \"Intro\",\n      \"Tools and Workflow\"\n    ]\n  },\n  \"dsan5100\": {\n    \"title\": \"Probabilistic Modeling and Statistical Computing\",\n    \"credits\": 3,\n    \"lectures\": [\n      \"Intro\",\n      \"Conditional Probability\"\n    ]\n  }\n}\n\n\n\nPython: json (built-in library, import json)\nR: jsonlite (install.packages(jsonlite))\nHelpful validator (for when .json file won’t load)"
  },
  {
    "objectID": "w04/index.html#other-formats",
    "href": "w04/index.html#other-formats",
    "title": "Week 4: Data Gathering and APIs",
    "section": "Other Formats",
    "text": "Other Formats\n\n.xls/.xlsx: Requires special libraries in Python/R\n\nPython: openpyxl\nR: readxl (part of tidyverse)\n\n.dta: Stata format, but can be read/written to in Python/R\n\nPython: Pandas has built-in pd.read_stata() and pd.to_stata()\nR: read_dta() from Haven library (part of tidyverse)"
  },
  {
    "objectID": "w04/index.html#scraping-html-with-requests-and-beautifulsoup",
    "href": "w04/index.html#scraping-html-with-requests-and-beautifulsoup",
    "title": "Week 4: Data Gathering and APIs",
    "section": "Scraping HTML with requests and BeautifulSoup",
    "text": "Scraping HTML with requests and BeautifulSoup\nrequests Documentation | BeautifulSoup Documentation\n\n\nCode\n# Get HTML\nimport requests\n# Perform request\nresponse = requests.get(\"https://en.wikipedia.org/wiki/Data_science\")\n# Parse HTML\nfrom bs4 import BeautifulSoup\nsoup = BeautifulSoup(response.text, 'html.parser')\nall_headers = soup.find_all(\"h2\")\nsection_headers = [h.find(\"span\", {'class': 'mw-headline'}).text for h in all_headers[1:]]\nsection_headers\n\n\n['Foundations', 'Etymology', 'Data Science and Data Analysis', 'History', 'See also', 'References']"
  },
  {
    "objectID": "w04/index.html#navigating-html-with-beautifulsoup",
    "href": "w04/index.html#navigating-html-with-beautifulsoup",
    "title": "Week 4: Data Gathering and APIs",
    "section": "Navigating HTML with BeautifulSoup",
    "text": "Navigating HTML with BeautifulSoup\n\nLet’s focus on this line from the previous slide:\n\nall_headers = soup.find_all(\"h2\")\n\nfind_all() is the key function for scraping!\nIf the HTML has a repeating structure (like rows in a table), find_all() can instantly parse this structure into a Python list."
  },
  {
    "objectID": "w04/index.html#the-power-of-find_all",
    "href": "w04/index.html#the-power-of-find_all",
    "title": "Week 4: Data Gathering and APIs",
    "section": "The Power of find_all()",
    "text": "The Power of find_all()\n\n\n\n\n\n\ndata_page.html\n\n&lt;div class=\"all-the-data\"&gt;\n    &lt;h4&gt;First Dataset&lt;/h4&gt;\n    &lt;div class=\"data-1\"&gt;\n        &lt;div class=\"dataval\"&gt;1&lt;/div&gt;\n        &lt;div class=\"dataval\"&gt;2&lt;/div&gt;\n        &lt;div class=\"dataval\"&gt;3&lt;/div&gt;\n    &lt;/div&gt;\n    &lt;h4&gt;Second Dataset&lt;/h4&gt;\n    &lt;div class=\"data-2\"&gt;\n        &lt;ul&gt;\n            &lt;li&gt;4.0&lt;/li&gt;\n            &lt;li&gt;5.5&lt;/li&gt;\n            &lt;li&gt;6.7&lt;/li&gt;\n        &lt;/ul&gt;\n    &lt;/div&gt;\n&lt;/div&gt;\n\nFigure 11: Data in page elements (&lt;div&gt;, &lt;li&gt;)\n\n\n\n\n\n    First Dataset\n    \n        1\n        2\n        3\n    \n    Second Dataset\n        \n            4.0\n            5.5\n            6.7\n        \n\nFigure 12: The code from Figure 11, rendered by your browser\n\n\n\n\n\n\n\nfrom bs4 import BeautifulSoup\nsoup = BeautifulSoup(page_html, 'html.parser')\nds1_elt = soup.find(\"div\", class_='data-1')\nds1 = [e.text for e in ds1_elt.find_all(\"div\")]\nds2_elt = soup.find(\"div\", {'class': 'data-2'})\nds2 = [e.text for e in ds2_elt.find_all(\"li\")]\n\nFigure 13: The BeautifulSoup code used to parse the HTML\n\n\n\n\n\nprint(f\"dataset-1: {ds1}\\ndataset-2: {ds2}\")\n\ndataset-1: ['1', '2', '3']\ndataset-2: ['4.0', '5.5', '6.7']\n\n\nFigure 14: Contents of the Python variables holding the parsed data"
  },
  {
    "objectID": "w04/index.html#parsing-html-tables",
    "href": "w04/index.html#parsing-html-tables",
    "title": "Week 4: Data Gathering and APIs",
    "section": "Parsing HTML Tables",
    "text": "Parsing HTML Tables\n\n\n\n\n\n\ntable_data.html\n\n&lt;table&gt;\n&lt;thead&gt;\n    &lt;tr&gt;\n        &lt;th&gt;X1&lt;/th&gt;&lt;th&gt;X2&lt;/th&gt;&lt;th&gt;X3&lt;/th&gt;\n    &lt;/tr&gt;\n&lt;/thead&gt;\n&lt;tbody&gt;\n    &lt;tr&gt;\n        &lt;td&gt;1&lt;/td&gt;&lt;td&gt;3&lt;/td&gt;&lt;td&gt;5&lt;/td&gt;\n    &lt;/tr&gt;\n    &lt;tr&gt;\n        &lt;td&gt;2&lt;/td&gt;&lt;td&gt;4&lt;/td&gt;&lt;td&gt;6&lt;/td&gt;\n    &lt;/tr&gt;\n&lt;/tbody&gt;\n&lt;/table&gt;\n\nFigure 15: Data in HTML table format\n\n\n\n\n\n\n\nX1\nX2\nX3\n\n\n\n\n1\n3\n5\n\n\n2\n4\n6\n\n\n\nFigure 16: The HTML table code, as rendered by your browser\n\n\n\n\n\n\n\nfrom bs4 import BeautifulSoup\nsoup = BeautifulSoup(table_html, 'html.parser')\nthead = soup.find(\"thead\")\nheaders = [e.text for e in thead.find_all(\"th\")]\ntbody = soup.find(\"tbody\")\nrows = tbody.find_all(\"tr\")\ndata = [[e.text for e in r.find_all(\"td\")]\n            for r in rows]\n\nFigure 17: The BeautifulSoup code used to parse the table HTML\n\n\n\n\n\nprint(f\"headers: {headers}\\ndata: {data}\")\n\nheaders: ['X1', 'X2', 'X3']\ndata: [['1', '3', '5'], ['2', '4', '6']]\n\n\nFigure 18: Contents of the Python variables holding the parsed data"
  },
  {
    "objectID": "w04/index.html#what-does-an-api-do",
    "href": "w04/index.html#what-does-an-api-do",
    "title": "Week 4: Data Gathering and APIs",
    "section": "What Does an API Do?",
    "text": "What Does an API Do?\nExposes endpoints for use by developers, without requiring them to know the nuts and bolts of your pipeline/service:\n\n\n\n\n\n\n\n\nExample\nEndpoint\nNot Exposed\n\n\n\n\nElectrical outlet\nSocket\nInternal wiring\n\n\nWater fountain\nAerator\nWater pump\n\n\nCar\nPedals, Steering wheel, etc.\nEngine\n\n\n\n\nWhen I’m teaching programming to students in refugee camps who may have never used a computer before, I try to use the idea of “robots”: a program is a robot trained to sit there and wait for inputs, then process them in some way and spit out some output. APIs really capture this notion, honestly."
  },
  {
    "objectID": "w04/index.html#example-math-api",
    "href": "w04/index.html#example-math-api",
    "title": "Week 4: Data Gathering and APIs",
    "section": "Example: Math API",
    "text": "Example: Math API\n\nBase URL: https://newton.vercel.app/api/v2/\nThe endpoint: factor\nThe argument: \"x^2 - 1\"\nThe request: https://newton.vercel.app/api/v2/factor/x^2-1\n\n\n\nCode\nimport requests\nresponse = requests.get(\"https://newton.vercel.app/api/v2/factor/x^2-1\")\nprint(response.json())\n\n\n{'operation': 'factor', 'expression': 'x^2-1', 'result': '(x - 1) (x + 1)'}"
  },
  {
    "objectID": "w04/index.html#math-api-endpoints",
    "href": "w04/index.html#math-api-endpoints",
    "title": "Week 4: Data Gathering and APIs",
    "section": "Math API Endpoints",
    "text": "Math API Endpoints\n\n\n\nOperation\nAPI Endpoint\nResult\n\n\n\n\nSimplify\n/simplify/2^2+2(2)\n8\n\n\nFactor\n/factor/x^2 + 2x\nx (x + 2)\n\n\nDerive\n/derive/x^2+2x\n2 x + 2\n\n\nIntegrate\n/integrate/x^2+2x\n1/3 x^3 + x^2 + C\n\n\nFind 0’s\n/zeroes/x^2+2x\n[-2, 0]\n\n\nFind Tangent\n/tangent/2|x^3\n12 x + -16\n\n\nArea Under Curve\n/area/2:4|x^3\n60\n\n\nCosine\n/cos/pi\n-1\n\n\nSine\n/sin/0\n0\n\n\nTangent\n/tan/0\n0"
  },
  {
    "objectID": "w04/index.html#authentication",
    "href": "w04/index.html#authentication",
    "title": "Week 4: Data Gathering and APIs",
    "section": "Authentication",
    "text": "Authentication\n\nUnlike the math API, most APIs do not allow requests to be made by anonymous requesters, and require authentication.\nFor example, you can access public GitHub repos anonymously, but to access private GitHub repos using GitHub’s API, you’ll need to authenticate that you are in fact the one making the request"
  },
  {
    "objectID": "w04/index.html#authentication-via-pygithub",
    "href": "w04/index.html#authentication-via-pygithub",
    "title": "Week 4: Data Gathering and APIs",
    "section": "Authentication via PyGithub",
    "text": "Authentication via PyGithub\n\n\n\n\n\n\nPyGithub Installation\n\n\n\nInstall using the following terminal/shell command [Documentation]\npip install PyGithub\n\n\nPyGithub can handle authentication for you. Example: this private repo in my account does not show up unless the request is authenticated (via a Personal Access Token)2:\n\n\n\n\n\n\nimport github\ng = github.Github()\ntry:\n    g.get_repo(\"jpowerj/private-repo-test\")\nexcept Exception as e:\n    print(e)\n\n404 {\"message\": \"Not Found\", \"documentation_url\": \"https://docs.github.com/rest/repos/repos#get-a-repository\"}\n\n\n\nFigure 19: Using the GitHub API without authenticationSource: github-auth.ipynb\n\n\n\n\n\n\n# Load the access token securely\nimport dotenv\ndotenv.load_dotenv(\"../.env\", override=True)\nimport os\nmy_access_token = os.getenv('GITHUB_TOKEN')\nimport github\n# Use the access token to make an API request\nauth = github.Auth.Token(my_access_token)\ng = github.Github(auth=auth)\ng.get_user().get_repo(\"private-repo-test\")\n\nRepository(full_name=\"jpowerj/private-repo-test\")\n\n\n\nFigure 20: Using the GitHub API with authenticationSource: github-auth.ipynb"
  },
  {
    "objectID": "w04/index.html#wikipedia-api",
    "href": "w04/index.html#wikipedia-api",
    "title": "Week 4: Data Gathering and APIs",
    "section": "Wikipedia API",
    "text": "Wikipedia API\nWikipedia API Demo Link"
  },
  {
    "objectID": "w04/index.html#google-scholar-api",
    "href": "w04/index.html#google-scholar-api",
    "title": "Week 4: Data Gathering and APIs",
    "section": "Google Scholar API",
    "text": "Google Scholar API\nGoogle Scholar API Demo Link"
  },
  {
    "objectID": "w04/index.html#news-api",
    "href": "w04/index.html#news-api",
    "title": "Week 4: Data Gathering and APIs",
    "section": "News API",
    "text": "News API\nNews API Lab Demo Link"
  },
  {
    "objectID": "w04/index.html#lab-assignment-overview",
    "href": "w04/index.html#lab-assignment-overview",
    "title": "Week 4: Data Gathering and APIs",
    "section": "Lab Assignment Overview",
    "text": "Lab Assignment Overview\nLab 2.1"
  },
  {
    "objectID": "w04/index.html#references",
    "href": "w04/index.html#references",
    "title": "Week 4: Data Gathering and APIs",
    "section": "References",
    "text": "References\n\n\nAgrawal, Monica, Marinka Zitnik, and Jure Leskovec. 2018. “Large-Scale Analysis of Disease Pathways in the Human Interactome.” In PACIFIC SYMPOSIUM on BIOCOMPUTING 2018: Proceedings of the Pacific Symposium, 111–22. World Scientific.\n\n\nMenczer, Filippo, Santo Fortunato, and Clayton A. Davis. 2020. A First Course in Network Science. Cambridge University Press."
  },
  {
    "objectID": "w04/index.html#scraping-html-with-httr2-and-xml2",
    "href": "w04/index.html#scraping-html-with-httr2-and-xml2",
    "title": "Week 4: Data Gathering and APIs",
    "section": "Scraping HTML with httr2 and xml2",
    "text": "Scraping HTML with httr2 and xml2\nhttr2 Documentation | xml2 Documentation\n\n\nCode\n# Get HTML\nlibrary(httr2)\nrequest_obj &lt;- request(\"https://en.wikipedia.org/wiki/Data_science\")\nresponse_obj &lt;- req_perform(request_obj)\n# Parse HTML\nlibrary(xml2)\n\n\n\nAttaching package: 'xml2'\n\n\nThe following object is masked from 'package:httr2':\n\n    url_parse\n\n\nCode\nhtml_obj &lt;- response_obj %&gt;% resp_body_html()\nhtml_obj %&gt;% xml_find_all('//h2//span[@class=\"mw-headline\"]')\n\n\n{xml_nodeset (6)}\n[1] &lt;span class=\"mw-headline\" id=\"Foundations\"&gt;Foundations&lt;/span&gt;\n[2] &lt;span class=\"mw-headline\" id=\"Etymology\"&gt;Etymology&lt;/span&gt;\n[3] &lt;span class=\"mw-headline\" id=\"Data_Science_and_Data_Analysis\"&gt;Data Scienc ...\n[4] &lt;span class=\"mw-headline\" id=\"History\"&gt;History&lt;/span&gt;\n[5] &lt;span class=\"mw-headline\" id=\"See_also\"&gt;See also&lt;/span&gt;\n[6] &lt;span class=\"mw-headline\" id=\"References\"&gt;References&lt;/span&gt;\n\n\n\n\nNote: httr2 is a re-written version of the original httr package, which is now deprecated. You’ll still see lots of code using httr, however, so it’s good to know how both versions work. Click here for a helpful vignette on the original httr library."
  },
  {
    "objectID": "w04/index.html#navigating-html-with-xpath",
    "href": "w04/index.html#navigating-html-with-xpath",
    "title": "Week 4: Data Gathering and APIs",
    "section": "Navigating HTML with XPath",
    "text": "Navigating HTML with XPath\nXPath Cheatsheet\n\nNotice the last line on the previous slide:\n\nhtml_obj %&gt;% xml_find_all('//h2//span[@class=\"mw-headline\"]')\n\nThe string passed to xml_find_all() is an XPath selector\n\n\n\nXPath selectors are used by many different libraries, including Selenium (which we’ll look at very soon) and jQuery (a standard extension to plain JavaScript allowing easy searching/manipulation of the DOM), so it’s good to learn it now!"
  },
  {
    "objectID": "w04/index.html#xpath-i-selecting-elements",
    "href": "w04/index.html#xpath-i-selecting-elements",
    "title": "Week 4: Data Gathering and APIs",
    "section": "XPath I: Selecting Elements",
    "text": "XPath I: Selecting Elements\n\n\nmypage.html\n\n&lt;div class=\"container\"&gt;\n  &lt;h1&gt;Header&lt;/h1&gt;\n  &lt;p id=\"page-content\"&gt;Content&lt;/p&gt;\n  &lt;img class=\"footer-image m-5\" src=\"footer.png\"&gt;\n&lt;/div&gt;\n\n\n'//div' matches all elements &lt;div&gt; in the document:\n&lt;div class=\"container\"&gt;\n  &lt;h1&gt;Header&lt;/h1&gt;\n  &lt;p id=\"page-content\"&gt;Content&lt;/p&gt;\n  &lt;img class=\"footer-image m-5\" src=\"footer.png\"&gt;\n&lt;/div&gt;\n'//div//img' matches &lt;img&gt; elements which are children of &lt;div&gt; elements:\n&lt;img class=\"footer-image m-5\" src=\"footer.png\"&gt;"
  },
  {
    "objectID": "w04/index.html#xpath-ii-filtering-by-attributes",
    "href": "w04/index.html#xpath-ii-filtering-by-attributes",
    "title": "Week 4: Data Gathering and APIs",
    "section": "XPath II: Filtering by Attributes",
    "text": "XPath II: Filtering by Attributes\n\n\nmypage.html\n\n&lt;div class=\"container\"&gt;\n  &lt;h1&gt;Header&lt;/h1&gt;\n  &lt;p id=\"page-content\"&gt;Content&lt;/p&gt;\n  &lt;img class=\"footer-image m-5\" src=\"footer.png\"&gt;\n&lt;/div&gt;\n\n\n'//p[id=\"page-content\"]' matches all &lt;p&gt; elements with id page-content3:\n&lt;p id=\"page-content\"&gt;Content&lt;/p&gt;\nMatching classes is a bit trickier:\n'//img[contains(concat(\" \", normalize-space(@class), \" \"), \" footer-image \")]'\nmatches all &lt;img&gt; elements with page-content as one of their classes4\n&lt;img class=\"footer-image m-5\" src=\"footer.png\"&gt;"
  },
  {
    "objectID": "w04/index.html#example-math-api-1",
    "href": "w04/index.html#example-math-api-1",
    "title": "Week 4: Data Gathering and APIs",
    "section": "Example: Math API",
    "text": "Example: Math API\n\nBase URL: https://newton.vercel.app/api/v2/\nThe endpoint: factor\nThe argument: \"x^2 - 1\"\nThe request: https://newton.vercel.app/api/v2/factor/x^2-1\n\n\n\nCode\nlibrary(httr2)\nrequest_obj &lt;- request(\"https://newton.vercel.app/api/v2/factor/x^2-1\")\nresponse_obj &lt;- req_perform(request_obj)\nwriteLines(response_obj %&gt;% resp_body_string())\n\n\n{\"operation\":\"factor\",\"expression\":\"x^2-1\",\"result\":\"(x - 1) (x + 1)\"}"
  },
  {
    "objectID": "w04/index.html#authentication-1",
    "href": "w04/index.html#authentication-1",
    "title": "Week 4: Data Gathering and APIs",
    "section": "Authentication",
    "text": "Authentication\n\nMost APIs don’t allow requests to be made by anonymous requesters, and require authentication.\nFor example, to access private GitHub repos using GitHub’s API, you’ll need to authenticate that you are in fact the one making the request"
  },
  {
    "objectID": "w04/index.html#authentication-via-gh",
    "href": "w04/index.html#authentication-via-gh",
    "title": "Week 4: Data Gathering and APIs",
    "section": "Authentication via GH",
    "text": "Authentication via GH\n\nThe GH library for R can handle this authentication process for you. For example, this private repo in my account does not show up if requested anonymously, but does show up when requested using GH with a Personal Access Token5:\n\n\n\nCode\nlibrary(gh)\nresult &lt;- gh(\"GET /repos/jpowerj/private-repo-test\")\nwriteLines(paste0(result$name, \": \",result$description))\n\n\nprivate-repo-test: Private repo example for DSAN5000"
  },
  {
    "objectID": "w04/index.html#footnotes",
    "href": "w04/index.html#footnotes",
    "title": "Week 4: Data Gathering and APIs",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nFor (much) more on this topic, see this page from Prisma, a high-level “wrapper” that auto-syncs your DB structure with a TypeScript schema, so your code knows exactly “what’s inside” a variable whose content was retrieved from the DB…↩︎\nYour code should 🚨never🚨 contain authentication info, especially when using GitHub. In this case, I created an OS environment variable called GITHUB_TOKEN containing my Personal Access Token, which I then loaded using os.getenv() and provided to PyGithub.↩︎\nIn HTML, ids are required to be unique to particular elements (and elements cannot have more than one id), meaning that this should only return a single element, for valid HTML code (not followed by all webpages!). Also note the double-quotes after id=, which are required in XPath.↩︎\nYour intuition may be to just use '//img[@class=\"footer-image\"]'. Sadly, however, this will match only elements with footer-image as their only class. i.e., it will match &lt;img class=\"footer-image\"&gt; but not &lt;img class=\"footer-image another-class\"&gt;. This will usually fail, since most elements on modern webpages have several classes. For example, if the site is using Bootstrap, &lt;p class=\"p-5 m-3\"&gt;&lt;/p&gt; creates a paragraph element with a padding of 5 pixels and a margin of 3 pixels.↩︎\nYour code should never contain authentication info, especially when using GitHub. In this case, I created an OS environment variable called GITHUB_TOKEN containing my Personal Access Token, which GH then uses to make authenticated requests.↩︎"
  },
  {
    "objectID": "w03/index.html",
    "href": "w03/index.html",
    "title": "Week 3: Data Science Workflow",
    "section": "",
    "text": "Open slides in new window →"
  },
  {
    "objectID": "w03/index.html#intranet-vs.-internet",
    "href": "w03/index.html#intranet-vs.-internet",
    "title": "Week 3: Data Science Workflow",
    "section": "Intranet vs. Internet",
    "text": "Intranet vs. Internet\n\nCrucial distinction: can set up a “mini-internet”, an intranet, within your own home\nOrganizations (businesses, government agencies) with security needs often do exactly this: link a set of computers and servers together, no outside access\n\n\n\n\n\n\n\nInternet = basically a giant intranet, open to the whole world"
  },
  {
    "objectID": "w03/index.html#key-building-blocks-locating-servers",
    "href": "w03/index.html#key-building-blocks-locating-servers",
    "title": "Week 3: Data Science Workflow",
    "section": "Key Building Blocks: Locating Servers",
    "text": "Key Building Blocks: Locating Servers\n\nIP Addresses (Internet Protocol addresses): Numeric addresses for uniquely identifying computers on a network\n\nGeorgetown University, for example, is allocated IP addresses between 141.161.0.0 and 141.161.255.255\n\nURLs (Uniform Resource Locators): The more human-readable website addresses you’re used to: google.com, georgetown.edu, etc.\n\nBuilt on top of IP addresses, via a directory which maps URLs → IP addresses\ngeorgetown.edu, for example, is really 23.185.0.21"
  },
  {
    "objectID": "w03/index.html#what-happens-when-i-visit-a-urlip",
    "href": "w03/index.html#what-happens-when-i-visit-a-urlip",
    "title": "Week 3: Data Science Workflow",
    "section": "What Happens When I Visit a URL/IP?",
    "text": "What Happens When I Visit a URL/IP?\n\nHTTP(S) (HyperText Transfer Protocol (Secure)): common syntax for web clients to make requests and servers to respond\n\nSeveral types of requests can be made: GET, POST, HEAD; for now, we focus on the GET request, the request your browser makes by default\n\nHTML (HyperText Markup Language): For specifying layout and content of page\n\nStructure is analogous to boxes of content: &lt;html&gt; box contains &lt;head&gt; (metadata, e.g., page title) and &lt;body&gt; (page content) boxes, &lt;body&gt; box contains e.g. header, footer, navigation bar, and main content of page.\nModern webpages also include CSS (Cascading Style Sheets) for styling this content, and Javascript2 for interactivity (changing/updating content)\nHTML allows linking to another page with a special anchor tag (&lt;a&gt;): &lt;a href=\"https://npr.org/\"&gt;news&lt;/a&gt; creates a link, so when you click “news”, browser will request (fetch the HTML for) the URL https://npr.org"
  },
  {
    "objectID": "w03/index.html#https-requests-in-action",
    "href": "w03/index.html#https-requests-in-action",
    "title": "Week 3: Data Science Workflow",
    "section": "HTTP(S) Requests in Action",
    "text": "HTTP(S) Requests in Action\n\n\n\nImage from Menczer, Fortunato, and Davis (2020, 90)"
  },
  {
    "objectID": "w03/index.html#how-does-a-web-server-work",
    "href": "w03/index.html#how-does-a-web-server-work",
    "title": "Week 3: Data Science Workflow",
    "section": "How Does a Web Server Work?",
    "text": "How Does a Web Server Work?\n\nWe use the term “server” metonymously3\n\nSometimes we mean the hardware, the box of processors and hard drives\nBut, sometimes we mean the software that runs on the hardware\n\nA web server, in the software sense, is a program that is always running, 24/7\nWaits for requests (via HTTPS), then serves HTML code in response (also via HTTPS)\n\n\n\n\n\n\n\nhello_server.py\n\nfrom flask import Flask\napp = Flask(__name__)\n\n@app.route(\"/\")\ndef hello_world():\n    return \"&lt;p&gt;Hello, World!&lt;/p&gt;\"\n@app.route(\"/hack\")\ndef hacker_detected():\n    return \"&lt;p&gt;Hacker detected, pls stop&lt;/p&gt;\"\n\n$ flask --app hello_server run\n * Serving Flask app 'hello_server'\n * Running on http://127.0.0.1:5000 (CTRL+C to quit)\n127.0.0.1 [06/Sep/2023 00:11:05] \"GET / HTTP\" 200\n127.0.0.1 [06/Sep/2023 00:11:06] \"GET /hack HTTP\" 200\nFigure 3: Basic web server (written in Flask)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 4: [Browser-parsed] responses to GET requests"
  },
  {
    "objectID": "w03/index.html#how-does-a-web-client-work",
    "href": "w03/index.html#how-does-a-web-client-work",
    "title": "Week 3: Data Science Workflow",
    "section": "How Does a Web Client Work?",
    "text": "How Does a Web Client Work?\n\n\nOnce the server has responded to your request, you still only have raw HTML code\nSo, the browser is the program that renders this raw HTML code as a visual, (possibly) interactive webpage\nAs a data scientist, the most important thing to know is that different browsers can render the same HTML differently!\n\n\n\n\nA headache when pages are accessed through laptops\nA nightmare when pages are accessed through laptops and mobile"
  },
  {
    "objectID": "w03/index.html#connecting-to-servers",
    "href": "w03/index.html#connecting-to-servers",
    "title": "Week 3: Data Science Workflow",
    "section": "Connecting to Servers",
    "text": "Connecting to Servers\n\nWe’ve talked about the shell on your local computer, as well as the Georgetown Domains shell\nWe used Georgetown Domains’ web interface to access that shell, but you can remotely connect to any other shell from your local computer using the ssh command!"
  },
  {
    "objectID": "w03/index.html#transferring-files-tofrom-servers",
    "href": "w03/index.html#transferring-files-tofrom-servers",
    "title": "Week 3: Data Science Workflow",
    "section": "Transferring Files to/from Servers",
    "text": "Transferring Files to/from Servers\n\nRecall the copy command, cp, for files on your local computer\nThere is a remote equivalent, scp (Secure Copy Protocol), which you can use to copy files to/from remote servers to your local computer"
  },
  {
    "objectID": "w03/index.html#important-alternative-rsync",
    "href": "w03/index.html#important-alternative-rsync",
    "title": "Week 3: Data Science Workflow",
    "section": "Important Alternative: rsync",
    "text": "Important Alternative: rsync\n\nSimilar to scp, with same syntax, except it synchronizes (only copies files which are different or missing)\n\n\n\nsync_files.sh\n\nrsync -avz source_directory/ user@remote_server:/path/to/destination/\n\n\n-a (“archive”) tells rsync you want it to copy recursively\n-v (“verbose”) tells rsync to print information as it copies\n-z (“zip/compress”) tells rsync to compress files before copying and then decompress them on the server (thus massively speeding up the transfer)\nhttps://explainshell.com/explain?cmd=rsync+-avz"
  },
  {
    "objectID": "w03/index.html#why-do-we-need-reproducible-research",
    "href": "w03/index.html#why-do-we-need-reproducible-research",
    "title": "Week 3: Data Science Workflow",
    "section": "Why Do We Need Reproducible Research?",
    "text": "Why Do We Need Reproducible Research?\n\nMain human motivations (Max Weber): Wealth, Prestige, Power → “TED talk circuit”\n\n\n\n\nNew York Times Magazine, October 18, 2017."
  },
  {
    "objectID": "w03/index.html#science-vs.-human-fallibility",
    "href": "w03/index.html#science-vs.-human-fallibility",
    "title": "Week 3: Data Science Workflow",
    "section": "Science vs. Human Fallibility",
    "text": "Science vs. Human Fallibility\n\nScientific method + replicability/pre-registration = “Tying ourselves to the mast”\n\n\n\n\nJohn William Waterhouse, Ulysses and the Sirens, Public domain, via Wikimedia Commons\n\n\n\nIf we aim to disprove (!) our hypotheses, and we pre-register our methodology, we are bound to discovering truth, even when it is disadvantageous to our lives…"
  },
  {
    "objectID": "w03/index.html#human-fallibility-is-winning",
    "href": "w03/index.html#human-fallibility-is-winning",
    "title": "Week 3: Data Science Workflow",
    "section": "Human Fallibility is Winning…",
    "text": "Human Fallibility is Winning…\n\nMore than 70% of researchers have tried and failed to reproduce another scientist’s experiments, and more than half have failed to reproduce their own experiments. Those are some of the telling figures that emerged from Nature’s survey of 1,576 researchers (Baker 2016)\n\n\n\n\nsource(\"../_globals.r\")\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(ggplot2)\nga_lawyers &lt;- c(21362, 22254, 23134, 23698, 24367, 24930, 25632, 26459, 27227, 27457)\nski_df &lt;- tibble::tribble(\n  ~year, ~varname, ~value,\n  2000, \"ski_revenue\", 1551,\n  2001, \"ski_revenue\", 1635,\n  2002, \"ski_revenue\", 1801,\n  2003, \"ski_revenue\", 1827,\n  2004, \"ski_revenue\", 1956,\n  2005, \"ski_revenue\", 1989,\n  2006, \"ski_revenue\", 2178,\n  2007, \"ski_revenue\", 2257,\n  2008, \"ski_revenue\", 2476,\n  2009, \"ski_revenue\", 2438,\n)\nski_mean &lt;- mean(ski_df$value)\nski_sd &lt;- sd(ski_df$value)\nski_df &lt;- ski_df %&gt;% mutate(val_scaled = 12*value, val_norm = (value - ski_mean)/ski_sd)\nlaw_df &lt;- tibble::tibble(year=2000:2009, varname=\"ga_lawyers\", value=ga_lawyers)\nlaw_mean &lt;- mean(law_df$value)\nlaw_sd &lt;- sd(law_df$value)\nlaw_df &lt;- law_df %&gt;% mutate(val_norm = (value - law_mean)/law_sd)\nspur_df &lt;- dplyr::bind_rows(ski_df, law_df)\nggplot(spur_df, aes(x=year, y=val_norm, color=factor(varname, labels = c(\"Ski Revenue\",\"Lawyers in Georgia\")))) +\n  stat_smooth(method=\"loess\", se=FALSE) +\n  geom_point(size=g_pointsize/4) +\n  labs(\n    fill=\"\",\n    title=\"Ski Revenue vs. Georgia Lawyers\",\n    x=\"Year\",\n    color=\"Correlation: 99.2%\",\n    linetype=NULL\n  ) +\n  dsan_theme(\"custom\", 18) +\n  scale_x_continuous(\n    breaks=seq(from=2000, to=2014, by=2)\n  ) +\n  #scale_y_continuous(\n  #  name=\"Total Revenue, Ski Facilities (Million USD)\",\n  #  sec.axis = sec_axis(~ . * law_sd + law_mean, name = \"Number of Lawyers in Georgia\")\n  #) +\n  scale_y_continuous(breaks = -1:1,\n    labels = ~ . * round(ski_sd,1) + round(ski_mean,1),\n    name=\"Total Revenue, Ski Facilities (Million USD)\",\n    sec.axis = sec_axis(~ . * law_sd + law_mean, name = \"Number of Lawyers in Georgia\")) +\n  expand_limits(x=2010) +\n  #geom_hline(aes(yintercept=x, color=\"Mean Values\"), as.data.frame(list(x=0)), linewidth=0.75, alpha=1.0, show.legend = TRUE) +\n  scale_color_manual(\n    breaks=c('Ski Revenue', 'Lawyers in Georgia'),\n    values=c('Ski Revenue'=cbPalette[1], 'Lawyers in Georgia'=cbPalette[2]))\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\ncor(ski_df$value, law_df$value)\n\n[1] 0.9921178"
  },
  {
    "objectID": "w03/index.html#r-vs.-rstudio-vs.-quarto",
    "href": "w03/index.html#r-vs.-rstudio-vs.-quarto",
    "title": "Week 3: Data Science Workflow",
    "section": "R vs. RStudio vs. Quarto",
    "text": "R vs. RStudio vs. Quarto\n\n\n\n\n\n\n\n\n\n\n\n\n\nGUI wrapper around R (Integrated Development Environment = IDE)\nRun blocks of R code (.qmd chunks)\n\n\n\nThe R Language \n\nProgramming language\nRuns scripts via Rscript &lt;script&gt;.r \n\n\n\n\n\n\n+\n\n\n\n\n\n\n\nGUI wrapper around Python (IDE)\nRun blocks of Python code (.ipynb cells)\n\n\n\n\nThe Python Language \n\nScripting language\nOn its own, just runs scripts via python &lt;script&gt;.py"
  },
  {
    "objectID": "w03/index.html#reproducibility-and-literate-programming",
    "href": "w03/index.html#reproducibility-and-literate-programming",
    "title": "Week 3: Data Science Workflow",
    "section": "Reproducibility and Literate Programming",
    "text": "Reproducibility and Literate Programming\n\nReproducible document: includes both the content (text, tables, figures) and the code or instructions required to generate that content.\n\nDesigned to ensure that others can reproduce the same document, including its data analysis, results, and visualizations, consistently and accurately.\ntldr: If you’re copying-and-pasting results from your code output to your results document, a red flag should go off in your head!\n\nLiterate programming is a coding and documentation approach where code and explanations of the code are combined in a single document.\n\nEmphasizes clear and understandable code by interleaving human-readable text (explanations, comments, and documentation) with executable code."
  },
  {
    "objectID": "w03/index.html#single-source-many-outputs",
    "href": "w03/index.html#single-source-many-outputs",
    "title": "Week 3: Data Science Workflow",
    "section": "Single Source, Many Outputs",
    "text": "Single Source, Many Outputs\n\nWe can create content (text, code, results, graphics) within a source document, and then use different weaving engines to create different document types:\n\n\n\n\nDocuments\n\nWeb pages (HTML)\nWord documents\nPDF files\n\nPresentations\n\nHTML\nPowerPoint\n\n\n\n\nWebsites/blogs\nBooks\nDashboards\nInteractive documents\nFormatted journal articles"
  },
  {
    "objectID": "w03/index.html#interactivity",
    "href": "w03/index.html#interactivity",
    "title": "Week 3: Data Science Workflow",
    "section": "Interactivity!",
    "text": "Interactivity!\n\nAre we “hiding something” by choosing a specific bin width? Make it transparent!"
  },
  {
    "objectID": "w03/index.html#git-vs.-github",
    "href": "w03/index.html#git-vs.-github",
    "title": "Week 3: Data Science Workflow",
    "section": "Git vs. GitHub",
    "text": "Git vs. GitHub\n(Important distinction!)\n\n\nGit \n\nCommand-line program\ngit init in shell to create\ngit add to track files\ngit commit to commit changes to tracked files\n\n\nGitHub \n\nCode hosting website\nCreate a repository (repo) for each project\nCan clone repos onto your local machine\n\n\n\n\ngit push/git pull: The link between the two!"
  },
  {
    "objectID": "w03/index.html#git-diagram",
    "href": "w03/index.html#git-diagram",
    "title": "Week 3: Data Science Workflow",
    "section": "Git Diagram",
    "text": "Git Diagram"
  },
  {
    "objectID": "w03/index.html#initializing-a-repo",
    "href": "w03/index.html#initializing-a-repo",
    "title": "Week 3: Data Science Workflow",
    "section": "Initializing a Repo",
    "text": "Initializing a Repo\n\nLet’s make a directory for our project called cool-project, and initialize a Git repo for it\n\n\nuser@hostname:~$ mkdir cool-project\nuser@hostname:~$ cd cool-project\nuser@hostname:~/cool-project$ git init\nInitialized empty Git repository in /home/user/cool-project/.git/\n\nThis creates a hidden folder, .git, in the directory:\n\n\nuser@hostname:~/cool-project$ ls -lah\ntotal 12K\ndrwxr-xr-x  3 user user 4.0K May 28 00:53 .\ndrwxr-xr-x 12 user user 4.0K May 28 00:53 ..\ndrwxr-xr-x  7 user user 4.0K May 28 00:53 .git\n\nThe Git Side: Local I"
  },
  {
    "objectID": "w03/index.html#adding-and-committing-a-file",
    "href": "w03/index.html#adding-and-committing-a-file",
    "title": "Week 3: Data Science Workflow",
    "section": "Adding and Committing a File",
    "text": "Adding and Committing a File\nWe’re writing Python code, so let’s create and track cool_code.py:\nuser@hostname:~/cool-project$ touch cool_code.py\nuser@hostname:~/cool-project$ git add cool_code.py\nuser@hostname:~/cool-project$ git status\nOn branch main\n\nNo commits yet\n\nChanges to be committed:\n  (use \"git rm --cached &lt;file&gt;...\" to unstage)\n        new file:   cool_code.py\n\nuser@hostname:~/cool-project$ git commit -m \"Initial version of cool_code.py\"\n[main (root-commit) b40dc25] Initial version of cool_code.py\n 1 file changed, 0 insertions(+), 0 deletions(-)\n create mode 100644 cool_code.py"
  },
  {
    "objectID": "w03/index.html#the-commit-log",
    "href": "w03/index.html#the-commit-log",
    "title": "Week 3: Data Science Workflow",
    "section": "The Commit Log",
    "text": "The Commit Log\n\nView the commit log using git log:\n\nuser@hostname:~/cool-project$ git log\ncommit b40dc252a3b7355cc4c28397fefe7911ff3c94b9 (HEAD -&gt; main)\nAuthor: Jeff Jacobs &lt;jjacobs3@cs.stanford.edu&gt;\nDate:   Sun May 28 00:57:16 2023 +0000\n\n    Initial version of cool_code.py\n\n\n\n\n\ngitGraph\n   commit id: \"b40dc25\""
  },
  {
    "objectID": "w03/index.html#making-changes",
    "href": "w03/index.html#making-changes",
    "title": "Week 3: Data Science Workflow",
    "section": "Making Changes",
    "text": "Making Changes\nuser@hostname:~/cool-project$ git status\nOn branch main\nnothing to commit, working tree clean\nuser@hostname:~/cool-project$ echo \"1 + 1\" &gt;&gt; cool_code.py\nuser@hostname:~/cool-project$ more cool_code.py\n1 + 1\nuser@hostname:~/cool-project$ git add cool_code.py\nuser@hostname:~/cool-project$ git status\nOn branch main\nChanges to be committed:\n  (use \"git restore --staged &lt;file&gt;...\" to unstage)\n        modified:   cool_code.py\n\nuser@hostname:~/cool-project$ git commit -m \"Added code to cool_code.py\"\n[main e3bc497] Added code to cool_code.py\n 1 file changed, 1 insertion(+)"
  },
  {
    "objectID": "w03/index.html#section",
    "href": "w03/index.html#section",
    "title": "Week 3: Data Science Workflow",
    "section": "",
    "text": "The git log will show the new version:\nuser@hostname:~/cool-project$ git log\ncommit e3bc497acbb5a487566ff2014dcd7b83d0c75224 (HEAD -&gt; main)\nAuthor: Jeff Jacobs &lt;jjacobs3@cs.stanford.edu&gt;\nDate:   Sun May 28 00:38:05 2023 +0000\n\n    Added code to cool_code.py\n\ncommit b40dc25b14c0426b06c8d182184e147853f3c12e\nAuthor: Jeff Jacobs &lt;jjacobs3@cs.stanford.edu&gt;\nDate:   Sun May 28 00:37:02 2023 +0000\n\n    Initial version of cool_code.py"
  },
  {
    "objectID": "w03/index.html#more-changes",
    "href": "w03/index.html#more-changes",
    "title": "Week 3: Data Science Workflow",
    "section": "More Changes",
    "text": "More Changes\nuser@hostname:~/cool-project$ echo \"2 + 2\" &gt;&gt; cool_code.py\nuser@hostname:~/cool-project$ more cool_code.py\n1 + 1\n2 + 2\nuser@hostname:~/cool-project$ git add cool_code.py\nuser@hostname:~/cool-project$ git status\nOn branch main\nChanges to be committed:\n  (use \"git restore --staged &lt;file&gt;...\" to unstage)\n        modified:   cool_code.py\n\nuser@hostname:~/cool-project$ git commit -m \"Second version of cool_code.py\"\n[main 4007db9] Second version of cool_code.py\n 1 file changed, 1 insertion(+)"
  },
  {
    "objectID": "w03/index.html#and-the-git-log",
    "href": "w03/index.html#and-the-git-log",
    "title": "Week 3: Data Science Workflow",
    "section": "And the git log",
    "text": "And the git log\nuser@hostname:~/cool-project$ git log\ncommit 4007db9a031ca134fe09eab840b2bc845366a9c1 (HEAD -&gt; main)\nAuthor: Jeff Jacobs &lt;jjacobs3@cs.stanford.edu&gt;\nDate:   Sun May 28 00:39:28 2023 +0000\n\n    Second version of cool_code.py\n\ncommit e3bc497acbb5a487566ff2014dcd7b83d0c75224\nAuthor: Jeff Jacobs &lt;jjacobs3@cs.stanford.edu&gt;\nDate:   Sun May 28 00:38:05 2023 +0000\n\n    Added code to cool_code.py\n\ncommit b40dc25b14c0426b06c8d182184e147853f3c12e\nAuthor: Jeff Jacobs &lt;jjacobs3@cs.stanford.edu&gt;\nDate:   Sun May 28 00:37:02 2023 +0000\n\n    Initial (empty) version of cool_code.py"
  },
  {
    "objectID": "w03/index.html#undoing-a-commit-i",
    "href": "w03/index.html#undoing-a-commit-i",
    "title": "Week 3: Data Science Workflow",
    "section": "Undoing a Commit I",
    "text": "Undoing a Commit I\nFirst check the git log to find the hash for the commit you want to revert back to:\ncommit e3bc497acbb5a487566ff2014dcd7b83d0c75224\nAuthor: Jeff Jacobs &lt;jjacobs3@cs.stanford.edu&gt;\nDate:   Sun May 28 00:38:05 2023 +0000\n\n    Added code to cool_code.py"
  },
  {
    "objectID": "w03/index.html#undoing-a-commit-ii",
    "href": "w03/index.html#undoing-a-commit-ii",
    "title": "Week 3: Data Science Workflow",
    "section": "Undoing a Commit II",
    "text": "Undoing a Commit II\n\n This is irreversable! \n\nuser@hostname:~/cool-project$ git reset --hard e3bc497ac\nHEAD is now at e3bc497 Added code to cool_code.py\nuser@hostname:~/cool-project$ git log\ncommit e3bc497acbb5a487566ff2014dcd7b83d0c75224 (HEAD -&gt; main)\nAuthor: Jeff Jacobs &lt;jjacobs3@cs.stanford.edu&gt;\nDate:   Sun May 28 00:38:05 2023 +0000\n\n    Added code to cool_code.py\n\ncommit b40dc25b14c0426b06c8d182184e147853f3c12e\nAuthor: Jeff Jacobs &lt;jjacobs3@cs.stanford.edu&gt;\nDate:   Sun May 28 00:37:02 2023 +0000\n\n    Initial (empty) version of cool_code.py"
  },
  {
    "objectID": "w03/index.html#onwards-and-upwards",
    "href": "w03/index.html#onwards-and-upwards",
    "title": "Week 3: Data Science Workflow",
    "section": "Onwards and Upwards",
    "text": "Onwards and Upwards\nuser@hostname:~/cool-project$ echo \"3 + 3\" &gt;&gt; cool_code.py\nuser@hostname:~/cool-project$ git add cool_code.py\nuser@hostname:~/cool-project$ git status\nOn branch main\nChanges to be committed:\n  (use \"git restore --staged &lt;file&gt;...\" to unstage)\n        modified:   cool_code.py\n\nuser@hostname:~/cool-project$ git commit -m \"Added different code to cool_code.py\"\n[main 700d955] Added different code to cool_code.py\n 1 file changed, 1 insertion(+)"
  },
  {
    "objectID": "w03/index.html#section-1",
    "href": "w03/index.html#section-1",
    "title": "Week 3: Data Science Workflow",
    "section": "",
    "text": "The final git log:\nuser@hostname:~/cool-project$ git log\ncommit 700d955faacb27d7b8bc464b9451851b5e319f20 (HEAD -&gt; main)\nAuthor: Jeff Jacobs &lt;jjacobs3@cs.stanford.edu&gt;\nDate:   Sun May 28 00:44:49 2023 +0000\n\n    Added different code to cool_code.py\n\ncommit e3bc497acbb5a487566ff2014dcd7b83d0c75224\nAuthor: Jeff Jacobs &lt;jjacobs3@cs.stanford.edu&gt;\nDate:   Sun May 28 00:38:05 2023 +0000\n\n    Added code to cool_code.py\n\ncommit b40dc25b14c0426b06c8d182184e147853f3c12e\nAuthor: Jeff Jacobs &lt;jjacobs3@cs.stanford.edu&gt;\nDate:   Sun May 28 00:37:02 2023 +0000\n\n    Initial (empty) version of cool_code.py"
  },
  {
    "objectID": "w03/index.html#but-why-these-diagrams",
    "href": "w03/index.html#but-why-these-diagrams",
    "title": "Week 3: Data Science Workflow",
    "section": "But Why These Diagrams?",
    "text": "But Why These Diagrams?\nEven the simplest projects can start to look like:\n\n\n\n\n\ngitGraph\n       commit id: \"537dd67\"\n       commit id: \"6639143\"\n       branch nice_feature\n       checkout nice_feature\n       commit id: \"937ded8\"\n       checkout main\n       commit id: \"9e6679c\"\n       checkout nice_feature\n       branch very_nice_feature\n       checkout very_nice_feature\n       commit id: \"7f4de03\"\n       checkout main\n       commit id: \"6df80c1\"\n       checkout nice_feature\n       commit id: \"bd0ebb8\"\n       checkout main\n       merge nice_feature id: \"9ff61cc\" tag: \"V 1.0.0\" type: HIGHLIGHT\n       checkout very_nice_feature\n       commit id: \"370613b\"\n       checkout main\n       commit id: \"9a07a97\""
  },
  {
    "objectID": "w03/index.html#the-github-side-remote",
    "href": "w03/index.html#the-github-side-remote",
    "title": "Week 3: Data Science Workflow",
    "section": "The GitHub Side: Remote",
    "text": "The GitHub Side: Remote"
  },
  {
    "objectID": "w03/index.html#an-empty-repo",
    "href": "w03/index.html#an-empty-repo",
    "title": "Week 3: Data Science Workflow",
    "section": "An Empty Repo",
    "text": "An Empty Repo"
  },
  {
    "objectID": "w03/index.html#refresh-after-git-push",
    "href": "w03/index.html#refresh-after-git-push",
    "title": "Week 3: Data Science Workflow",
    "section": "Refresh after git push",
    "text": "Refresh after git push"
  },
  {
    "objectID": "w03/index.html#commit-history",
    "href": "w03/index.html#commit-history",
    "title": "Week 3: Data Science Workflow",
    "section": "Commit History",
    "text": "Commit History"
  },
  {
    "objectID": "w03/index.html#checking-the-diff",
    "href": "w03/index.html#checking-the-diff",
    "title": "Week 3: Data Science Workflow",
    "section": "Checking the diff",
    "text": "Checking the diff"
  },
  {
    "objectID": "w03/index.html#web-development",
    "href": "w03/index.html#web-development",
    "title": "Week 3: Data Science Workflow",
    "section": "Web Development",
    "text": "Web Development\n\n\n\n\n\n\n\n\n\nFrontend   \nBackend   \n\n\n\n\nLow Level\nHTML/CSS/JavaScript\nGitHub Pages\n\n\nMiddle Level\nJS Libraries\nPHP, SQL\n\n\nHigh Level\nReact, Next.js\nNode.js, Vercel\n\n\n\n\nFrontend icons: UI+UI elements, what the user sees (on the screen), user experience (UX), data visualization Backend icons: Databases, Security"
  },
  {
    "objectID": "w03/index.html#getting-content-onto-the-internet",
    "href": "w03/index.html#getting-content-onto-the-internet",
    "title": "Week 3: Data Science Workflow",
    "section": "Getting Content onto the Internet",
    "text": "Getting Content onto the Internet\n\n\n\n\nStep 1: index.html\n\n\nStep 2: Create GitHub repository\n\n\nStep 3: git init, git add -A ., git push\n\n\nStep 4: Enable GitHub Pages in repo settings\n\n\nStep 5: &lt;username&gt;.github.io!"
  },
  {
    "objectID": "w03/index.html#deploying-from-a-branchfolder",
    "href": "w03/index.html#deploying-from-a-branchfolder",
    "title": "Week 3: Data Science Workflow",
    "section": "Deploying from a Branch/Folder",
    "text": "Deploying from a Branch/Folder"
  },
  {
    "objectID": "w03/index.html#lab-demonstration-1-transferring-files",
    "href": "w03/index.html#lab-demonstration-1-transferring-files",
    "title": "Week 3: Data Science Workflow",
    "section": "Lab Demonstration 1: Transferring Files",
    "text": "Lab Demonstration 1: Transferring Files"
  },
  {
    "objectID": "w03/index.html#lab-demonstration-2-quarto",
    "href": "w03/index.html#lab-demonstration-2-quarto",
    "title": "Week 3: Data Science Workflow",
    "section": "Lab Demonstration 2: Quarto",
    "text": "Lab Demonstration 2: Quarto"
  },
  {
    "objectID": "w03/index.html#lab-demonstration-3-git-and-github",
    "href": "w03/index.html#lab-demonstration-3-git-and-github",
    "title": "Week 3: Data Science Workflow",
    "section": "Lab Demonstration 3: Git and GitHub",
    "text": "Lab Demonstration 3: Git and GitHub"
  },
  {
    "objectID": "w03/index.html#assignment-overview",
    "href": "w03/index.html#assignment-overview",
    "title": "Week 3: Data Science Workflow",
    "section": "Assignment Overview",
    "text": "Assignment Overview\n\nCreate a repo on your private GitHub account called 5000-lab-1.2\nClone the repo to your local machine with git clone\nCreate a blank Quarto website project, then use a .bib file to add citations\nAdd content to index.qmd\nAdd content to about.ipynb\nBuild a simple presentation in slides/slides.ipynb using the revealjs format\nRender the website using quarto render\nSync your changes to GitHub\nUse rsync or scp to copy the _site directory to your GU domains server (within ~/public_html)\nCreate a Zotero (or Mendeley) account, download the software, and add at least one reference to your site by syncing the .bib file"
  },
  {
    "objectID": "w03/index.html#references",
    "href": "w03/index.html#references",
    "title": "Week 3: Data Science Workflow",
    "section": "References",
    "text": "References\n\n\nBaker, Monya. 2016. “1,500 Scientists Lift the Lid on Reproducibility.” Nature 533 (7604): 452–54. https://doi.org/10.1038/533452a.\n\n\nMenczer, Filippo, Santo Fortunato, and Clayton A. Davis. 2020. A First Course in Network Science. Cambridge University Press."
  },
  {
    "objectID": "w03/index.html#footnotes",
    "href": "w03/index.html#footnotes",
    "title": "Week 3: Data Science Workflow",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nTo see this, you can open your Terminal and run the ping command: ping georgetown.edu.↩︎\nIncredibly, despite the name, Javascript has absolutely nothing to do with the Java programming language…↩︎\nSorry for jargon: it just means using the same word for different levels of a system (dangerous when talking computers!)↩︎"
  },
  {
    "objectID": "w03/slides.html#intranet-vs.-internet",
    "href": "w03/slides.html#intranet-vs.-internet",
    "title": "Week 3: Data Science Workflow",
    "section": "Intranet vs. Internet",
    "text": "Intranet vs. Internet\n\nCrucial distinction: can set up a “mini-internet”, an intranet, within your own home\nOrganizations (businesses, government agencies) with security needs often do exactly this: link a set of computers and servers together, no outside access\n\n\n\nInternet = basically a giant intranet, open to the whole world"
  },
  {
    "objectID": "w03/slides.html#key-building-blocks-locating-servers",
    "href": "w03/slides.html#key-building-blocks-locating-servers",
    "title": "Week 3: Data Science Workflow",
    "section": "Key Building Blocks: Locating Servers",
    "text": "Key Building Blocks: Locating Servers\n\nIP Addresses (Internet Protocol addresses): Numeric addresses for uniquely identifying computers on a network\n\nGeorgetown University, for example, is allocated IP addresses between 141.161.0.0 and 141.161.255.255\n\nURLs (Uniform Resource Locators): The more human-readable website addresses you’re used to: google.com, georgetown.edu, etc.\n\nBuilt on top of IP addresses, via a directory which maps URLs → IP addresses\ngeorgetown.edu, for example, is really 23.185.0.21\n\n\nTo see this, you can open your Terminal and run the ping command: ping georgetown.edu."
  },
  {
    "objectID": "w03/slides.html#what-happens-when-i-visit-a-urlip",
    "href": "w03/slides.html#what-happens-when-i-visit-a-urlip",
    "title": "Week 3: Data Science Workflow",
    "section": "What Happens When I Visit a URL/IP?",
    "text": "What Happens When I Visit a URL/IP?\n\nHTTP(S) (HyperText Transfer Protocol (Secure)): common syntax for web clients to make requests and servers to respond\n\nSeveral types of requests can be made: GET, POST, HEAD; for now, we focus on the GET request, the request your browser makes by default\n\nHTML (HyperText Markup Language): For specifying layout and content of page\n\nStructure is analogous to boxes of content: &lt;html&gt; box contains &lt;head&gt; (metadata, e.g., page title) and &lt;body&gt; (page content) boxes, &lt;body&gt; box contains e.g. header, footer, navigation bar, and main content of page.\nModern webpages also include CSS (Cascading Style Sheets) for styling this content, and Javascript1 for interactivity (changing/updating content)\nHTML allows linking to another page with a special anchor tag (&lt;a&gt;): &lt;a href=\"https://npr.org/\"&gt;news&lt;/a&gt; creates a link, so when you click “news”, browser will request (fetch the HTML for) the URL https://npr.org\n\n\nIncredibly, despite the name, Javascript has absolutely nothing to do with the Java programming language…"
  },
  {
    "objectID": "w03/slides.html#https-requests-in-action",
    "href": "w03/slides.html#https-requests-in-action",
    "title": "Week 3: Data Science Workflow",
    "section": "HTTP(S) Requests in Action",
    "text": "HTTP(S) Requests in Action\n\nImage from Menczer, Fortunato, and Davis (2020, 90)"
  },
  {
    "objectID": "w03/slides.html#how-does-a-web-server-work",
    "href": "w03/slides.html#how-does-a-web-server-work",
    "title": "Week 3: Data Science Workflow",
    "section": "How Does a Web Server Work?",
    "text": "How Does a Web Server Work?\n\nWe use the term “server” metonymously1\n\nSometimes we mean the hardware, the box of processors and hard drives\nBut, sometimes we mean the software that runs on the hardware\n\nA web server, in the software sense, is a program that is always running, 24/7\nWaits for requests (via HTTPS), then serves HTML code in response (also via HTTPS)\n\n\n\n\n\n\n\nhello_server.py\n\nfrom flask import Flask\napp = Flask(__name__)\n\n@app.route(\"/\")\ndef hello_world():\n    return \"&lt;p&gt;Hello, World!&lt;/p&gt;\"\n@app.route(\"/hack\")\ndef hacker_detected():\n    return \"&lt;p&gt;Hacker detected, pls stop&lt;/p&gt;\"\n\n$ flask --app hello_server run\n * Serving Flask app 'hello_server'\n * Running on http://127.0.0.1:5000 (CTRL+C to quit)\n127.0.0.1 [06/Sep/2023 00:11:05] \"GET / HTTP\" 200\n127.0.0.1 [06/Sep/2023 00:11:06] \"GET /hack HTTP\" 200\nFigure 3: Basic web server (written in Flask)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 4: [Browser-parsed] responses to GET requests\n\n\n\n\nSorry for jargon: it just means using the same word for different levels of a system (dangerous when talking computers!)"
  },
  {
    "objectID": "w03/slides.html#how-does-a-web-client-work",
    "href": "w03/slides.html#how-does-a-web-client-work",
    "title": "Week 3: Data Science Workflow",
    "section": "How Does a Web Client Work?",
    "text": "How Does a Web Client Work?\n\n\nOnce the server has responded to your request, you still only have raw HTML code\nSo, the browser is the program that renders this raw HTML code as a visual, (possibly) interactive webpage\nAs a data scientist, the most important thing to know is that different browsers can render the same HTML differently!\n\n\n\n\nA headache when pages are accessed through laptops\nA nightmare when pages are accessed through laptops and mobile"
  },
  {
    "objectID": "w03/slides.html#connecting-to-servers",
    "href": "w03/slides.html#connecting-to-servers",
    "title": "Week 3: Data Science Workflow",
    "section": "Connecting to Servers",
    "text": "Connecting to Servers\n\nWe’ve talked about the shell on your local computer, as well as the Georgetown Domains shell\nWe used Georgetown Domains’ web interface to access that shell, but you can remotely connect to any other shell from your local computer using the ssh command!"
  },
  {
    "objectID": "w03/slides.html#transferring-files-tofrom-servers",
    "href": "w03/slides.html#transferring-files-tofrom-servers",
    "title": "Week 3: Data Science Workflow",
    "section": "Transferring Files to/from Servers",
    "text": "Transferring Files to/from Servers\n\nRecall the copy command, cp, for files on your local computer\nThere is a remote equivalent, scp (Secure Copy Protocol), which you can use to copy files to/from remote servers to your local computer"
  },
  {
    "objectID": "w03/slides.html#important-alternative-rsync",
    "href": "w03/slides.html#important-alternative-rsync",
    "title": "Week 3: Data Science Workflow",
    "section": "Important Alternative: rsync",
    "text": "Important Alternative: rsync\n\nSimilar to scp, with same syntax, except it synchronizes (only copies files which are different or missing)\n\n\n\nsync_files.sh\n\nrsync -avz source_directory/ user@remote_server:/path/to/destination/\n\n\n-a (“archive”) tells rsync you want it to copy recursively\n-v (“verbose”) tells rsync to print information as it copies\n-z (“zip/compress”) tells rsync to compress files before copying and then decompress them on the server (thus massively speeding up the transfer)\nhttps://explainshell.com/explain?cmd=rsync+-avz"
  },
  {
    "objectID": "w03/slides.html#why-do-we-need-reproducible-research",
    "href": "w03/slides.html#why-do-we-need-reproducible-research",
    "title": "Week 3: Data Science Workflow",
    "section": "Why Do We Need Reproducible Research?",
    "text": "Why Do We Need Reproducible Research?\n\nMain human motivations (Max Weber): Wealth, Prestige, Power → “TED talk circuit”\n\n\nNew York Times Magazine, October 18, 2017."
  },
  {
    "objectID": "w03/slides.html#science-vs.-human-fallibility",
    "href": "w03/slides.html#science-vs.-human-fallibility",
    "title": "Week 3: Data Science Workflow",
    "section": "Science vs. Human Fallibility",
    "text": "Science vs. Human Fallibility\n\nScientific method + replicability/pre-registration = “Tying ourselves to the mast”\n\n\nJohn William Waterhouse, Ulysses and the Sirens, Public domain, via Wikimedia Commons\nIf we aim to disprove (!) our hypotheses, and we pre-register our methodology, we are bound to discovering truth, even when it is disadvantageous to our lives…"
  },
  {
    "objectID": "w03/slides.html#human-fallibility-is-winning",
    "href": "w03/slides.html#human-fallibility-is-winning",
    "title": "Week 3: Data Science Workflow",
    "section": "Human Fallibility is Winning…",
    "text": "Human Fallibility is Winning…\n\nMore than 70% of researchers have tried and failed to reproduce another scientist’s experiments, and more than half have failed to reproduce their own experiments. Those are some of the telling figures that emerged from Nature’s survey of 1,576 researchers (Baker 2016)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncor(ski_df$value, law_df$value)\n\n[1] 0.9921178"
  },
  {
    "objectID": "w03/slides.html#r-vs.-rstudio-vs.-quarto",
    "href": "w03/slides.html#r-vs.-rstudio-vs.-quarto",
    "title": "Week 3: Data Science Workflow",
    "section": "R vs. RStudio vs. Quarto",
    "text": "R vs. RStudio vs. Quarto\n\n\n\n\n\n\n\n\n\n\n\n\n\nGUI wrapper around R (Integrated Development Environment = IDE)\nRun blocks of R code (.qmd chunks)\n\n\n\nThe R Language \n\nProgramming language\nRuns scripts via Rscript &lt;script&gt;.r \n\n\n\n\n\n\n+\n\n\n\n\n\n\n\nGUI wrapper around Python (IDE)\nRun blocks of Python code (.ipynb cells)\n\n\n\n\nThe Python Language \n\nScripting language\nOn its own, just runs scripts via python &lt;script&gt;.py"
  },
  {
    "objectID": "w03/slides.html#reproducibility-and-literate-programming",
    "href": "w03/slides.html#reproducibility-and-literate-programming",
    "title": "Week 3: Data Science Workflow",
    "section": "Reproducibility and Literate Programming",
    "text": "Reproducibility and Literate Programming\n\nReproducible document: includes both the content (text, tables, figures) and the code or instructions required to generate that content.\n\nDesigned to ensure that others can reproduce the same document, including its data analysis, results, and visualizations, consistently and accurately.\ntldr: If you’re copying-and-pasting results from your code output to your results document, a red flag should go off in your head!\n\nLiterate programming is a coding and documentation approach where code and explanations of the code are combined in a single document.\n\nEmphasizes clear and understandable code by interleaving human-readable text (explanations, comments, and documentation) with executable code."
  },
  {
    "objectID": "w03/slides.html#single-source-many-outputs",
    "href": "w03/slides.html#single-source-many-outputs",
    "title": "Week 3: Data Science Workflow",
    "section": "Single Source, Many Outputs",
    "text": "Single Source, Many Outputs\n\nWe can create content (text, code, results, graphics) within a source document, and then use different weaving engines to create different document types:\n\n\n\n\nDocuments\n\nWeb pages (HTML)\nWord documents\nPDF files\n\nPresentations\n\nHTML\nPowerPoint\n\n\n\n\nWebsites/blogs\nBooks\nDashboards\nInteractive documents\nFormatted journal articles"
  },
  {
    "objectID": "w03/slides.html#interactivity",
    "href": "w03/slides.html#interactivity",
    "title": "Week 3: Data Science Workflow",
    "section": "Interactivity!",
    "text": "Interactivity!\n\nAre we “hiding something” by choosing a specific bin width? Make it transparent!"
  },
  {
    "objectID": "w03/slides.html#git-vs.-github",
    "href": "w03/slides.html#git-vs.-github",
    "title": "Week 3: Data Science Workflow",
    "section": "Git vs. GitHub",
    "text": "Git vs. GitHub\n(Important distinction!)\n\n\nGit \n\nCommand-line program\ngit init in shell to create\ngit add to track files\ngit commit to commit changes to tracked files\n\n\nGitHub \n\nCode hosting website\nCreate a repository (repo) for each project\nCan clone repos onto your local machine\n\n\n\n\ngit push/git pull: The link between the two!"
  },
  {
    "objectID": "w03/slides.html#git-diagram",
    "href": "w03/slides.html#git-diagram",
    "title": "Week 3: Data Science Workflow",
    "section": "Git Diagram",
    "text": "Git Diagram"
  },
  {
    "objectID": "w03/slides.html#initializing-a-repo",
    "href": "w03/slides.html#initializing-a-repo",
    "title": "Week 3: Data Science Workflow",
    "section": "Initializing a Repo",
    "text": "Initializing a Repo\n\nLet’s make a directory for our project called cool-project, and initialize a Git repo for it\n\n\nuser@hostname:~$ mkdir cool-project\nuser@hostname:~$ cd cool-project\nuser@hostname:~/cool-project$ git init\nInitialized empty Git repository in /home/user/cool-project/.git/\n\nThis creates a hidden folder, .git, in the directory:\n\n\nuser@hostname:~/cool-project$ ls -lah\ntotal 12K\ndrwxr-xr-x  3 user user 4.0K May 28 00:53 .\ndrwxr-xr-x 12 user user 4.0K May 28 00:53 ..\ndrwxr-xr-x  7 user user 4.0K May 28 00:53 .git\n\nThe Git Side: Local I"
  },
  {
    "objectID": "w03/slides.html#adding-and-committing-a-file",
    "href": "w03/slides.html#adding-and-committing-a-file",
    "title": "Week 3: Data Science Workflow",
    "section": "Adding and Committing a File",
    "text": "Adding and Committing a File\nWe’re writing Python code, so let’s create and track cool_code.py:\nuser@hostname:~/cool-project$ touch cool_code.py\nuser@hostname:~/cool-project$ git add cool_code.py\nuser@hostname:~/cool-project$ git status\nOn branch main\n\nNo commits yet\n\nChanges to be committed:\n  (use \"git rm --cached &lt;file&gt;...\" to unstage)\n        new file:   cool_code.py\n\nuser@hostname:~/cool-project$ git commit -m \"Initial version of cool_code.py\"\n[main (root-commit) b40dc25] Initial version of cool_code.py\n 1 file changed, 0 insertions(+), 0 deletions(-)\n create mode 100644 cool_code.py"
  },
  {
    "objectID": "w03/slides.html#the-commit-log",
    "href": "w03/slides.html#the-commit-log",
    "title": "Week 3: Data Science Workflow",
    "section": "The Commit Log",
    "text": "The Commit Log\n\nView the commit log using git log:\n\nuser@hostname:~/cool-project$ git log\ncommit b40dc252a3b7355cc4c28397fefe7911ff3c94b9 (HEAD -&gt; main)\nAuthor: Jeff Jacobs &lt;jjacobs3@cs.stanford.edu&gt;\nDate:   Sun May 28 00:57:16 2023 +0000\n\n    Initial version of cool_code.py\n\n\n\n\n\ngitGraph\n   commit id: \"b40dc25\""
  },
  {
    "objectID": "w03/slides.html#making-changes",
    "href": "w03/slides.html#making-changes",
    "title": "Week 3: Data Science Workflow",
    "section": "Making Changes",
    "text": "Making Changes\nuser@hostname:~/cool-project$ git status\nOn branch main\nnothing to commit, working tree clean\nuser@hostname:~/cool-project$ echo \"1 + 1\" &gt;&gt; cool_code.py\nuser@hostname:~/cool-project$ more cool_code.py\n1 + 1\nuser@hostname:~/cool-project$ git add cool_code.py\nuser@hostname:~/cool-project$ git status\nOn branch main\nChanges to be committed:\n  (use \"git restore --staged &lt;file&gt;...\" to unstage)\n        modified:   cool_code.py\n\nuser@hostname:~/cool-project$ git commit -m \"Added code to cool_code.py\"\n[main e3bc497] Added code to cool_code.py\n 1 file changed, 1 insertion(+)"
  },
  {
    "objectID": "w03/slides.html#section",
    "href": "w03/slides.html#section",
    "title": "Week 3: Data Science Workflow",
    "section": "",
    "text": "The git log will show the new version:\nuser@hostname:~/cool-project$ git log\ncommit e3bc497acbb5a487566ff2014dcd7b83d0c75224 (HEAD -&gt; main)\nAuthor: Jeff Jacobs &lt;jjacobs3@cs.stanford.edu&gt;\nDate:   Sun May 28 00:38:05 2023 +0000\n\n    Added code to cool_code.py\n\ncommit b40dc25b14c0426b06c8d182184e147853f3c12e\nAuthor: Jeff Jacobs &lt;jjacobs3@cs.stanford.edu&gt;\nDate:   Sun May 28 00:37:02 2023 +0000\n\n    Initial version of cool_code.py"
  },
  {
    "objectID": "w03/slides.html#more-changes",
    "href": "w03/slides.html#more-changes",
    "title": "Week 3: Data Science Workflow",
    "section": "More Changes",
    "text": "More Changes\nuser@hostname:~/cool-project$ echo \"2 + 2\" &gt;&gt; cool_code.py\nuser@hostname:~/cool-project$ more cool_code.py\n1 + 1\n2 + 2\nuser@hostname:~/cool-project$ git add cool_code.py\nuser@hostname:~/cool-project$ git status\nOn branch main\nChanges to be committed:\n  (use \"git restore --staged &lt;file&gt;...\" to unstage)\n        modified:   cool_code.py\n\nuser@hostname:~/cool-project$ git commit -m \"Second version of cool_code.py\"\n[main 4007db9] Second version of cool_code.py\n 1 file changed, 1 insertion(+)"
  },
  {
    "objectID": "w03/slides.html#and-the-git-log",
    "href": "w03/slides.html#and-the-git-log",
    "title": "Week 3: Data Science Workflow",
    "section": "And the git log",
    "text": "And the git log\nuser@hostname:~/cool-project$ git log\ncommit 4007db9a031ca134fe09eab840b2bc845366a9c1 (HEAD -&gt; main)\nAuthor: Jeff Jacobs &lt;jjacobs3@cs.stanford.edu&gt;\nDate:   Sun May 28 00:39:28 2023 +0000\n\n    Second version of cool_code.py\n\ncommit e3bc497acbb5a487566ff2014dcd7b83d0c75224\nAuthor: Jeff Jacobs &lt;jjacobs3@cs.stanford.edu&gt;\nDate:   Sun May 28 00:38:05 2023 +0000\n\n    Added code to cool_code.py\n\ncommit b40dc25b14c0426b06c8d182184e147853f3c12e\nAuthor: Jeff Jacobs &lt;jjacobs3@cs.stanford.edu&gt;\nDate:   Sun May 28 00:37:02 2023 +0000\n\n    Initial (empty) version of cool_code.py"
  },
  {
    "objectID": "w03/slides.html#undoing-a-commit-i",
    "href": "w03/slides.html#undoing-a-commit-i",
    "title": "Week 3: Data Science Workflow",
    "section": "Undoing a Commit I",
    "text": "Undoing a Commit I\nFirst check the git log to find the hash for the commit you want to revert back to:\ncommit e3bc497acbb5a487566ff2014dcd7b83d0c75224\nAuthor: Jeff Jacobs &lt;jjacobs3@cs.stanford.edu&gt;\nDate:   Sun May 28 00:38:05 2023 +0000\n\n    Added code to cool_code.py"
  },
  {
    "objectID": "w03/slides.html#undoing-a-commit-ii",
    "href": "w03/slides.html#undoing-a-commit-ii",
    "title": "Week 3: Data Science Workflow",
    "section": "Undoing a Commit II",
    "text": "Undoing a Commit II\n\n This is irreversable! \n\nuser@hostname:~/cool-project$ git reset --hard e3bc497ac\nHEAD is now at e3bc497 Added code to cool_code.py\nuser@hostname:~/cool-project$ git log\ncommit e3bc497acbb5a487566ff2014dcd7b83d0c75224 (HEAD -&gt; main)\nAuthor: Jeff Jacobs &lt;jjacobs3@cs.stanford.edu&gt;\nDate:   Sun May 28 00:38:05 2023 +0000\n\n    Added code to cool_code.py\n\ncommit b40dc25b14c0426b06c8d182184e147853f3c12e\nAuthor: Jeff Jacobs &lt;jjacobs3@cs.stanford.edu&gt;\nDate:   Sun May 28 00:37:02 2023 +0000\n\n    Initial (empty) version of cool_code.py"
  },
  {
    "objectID": "w03/slides.html#onwards-and-upwards",
    "href": "w03/slides.html#onwards-and-upwards",
    "title": "Week 3: Data Science Workflow",
    "section": "Onwards and Upwards",
    "text": "Onwards and Upwards\nuser@hostname:~/cool-project$ echo \"3 + 3\" &gt;&gt; cool_code.py\nuser@hostname:~/cool-project$ git add cool_code.py\nuser@hostname:~/cool-project$ git status\nOn branch main\nChanges to be committed:\n  (use \"git restore --staged &lt;file&gt;...\" to unstage)\n        modified:   cool_code.py\n\nuser@hostname:~/cool-project$ git commit -m \"Added different code to cool_code.py\"\n[main 700d955] Added different code to cool_code.py\n 1 file changed, 1 insertion(+)"
  },
  {
    "objectID": "w03/slides.html#section-1",
    "href": "w03/slides.html#section-1",
    "title": "Week 3: Data Science Workflow",
    "section": "",
    "text": "The final git log:\nuser@hostname:~/cool-project$ git log\ncommit 700d955faacb27d7b8bc464b9451851b5e319f20 (HEAD -&gt; main)\nAuthor: Jeff Jacobs &lt;jjacobs3@cs.stanford.edu&gt;\nDate:   Sun May 28 00:44:49 2023 +0000\n\n    Added different code to cool_code.py\n\ncommit e3bc497acbb5a487566ff2014dcd7b83d0c75224\nAuthor: Jeff Jacobs &lt;jjacobs3@cs.stanford.edu&gt;\nDate:   Sun May 28 00:38:05 2023 +0000\n\n    Added code to cool_code.py\n\ncommit b40dc25b14c0426b06c8d182184e147853f3c12e\nAuthor: Jeff Jacobs &lt;jjacobs3@cs.stanford.edu&gt;\nDate:   Sun May 28 00:37:02 2023 +0000\n\n    Initial (empty) version of cool_code.py"
  },
  {
    "objectID": "w03/slides.html#but-why-these-diagrams",
    "href": "w03/slides.html#but-why-these-diagrams",
    "title": "Week 3: Data Science Workflow",
    "section": "But Why These Diagrams?",
    "text": "But Why These Diagrams?\nEven the simplest projects can start to look like:\n\n\n\n\n\ngitGraph\n       commit id: \"537dd67\"\n       commit id: \"6639143\"\n       branch nice_feature\n       checkout nice_feature\n       commit id: \"937ded8\"\n       checkout main\n       commit id: \"9e6679c\"\n       checkout nice_feature\n       branch very_nice_feature\n       checkout very_nice_feature\n       commit id: \"7f4de03\"\n       checkout main\n       commit id: \"6df80c1\"\n       checkout nice_feature\n       commit id: \"bd0ebb8\"\n       checkout main\n       merge nice_feature id: \"9ff61cc\" tag: \"V 1.0.0\" type: HIGHLIGHT\n       checkout very_nice_feature\n       commit id: \"370613b\"\n       checkout main\n       commit id: \"9a07a97\""
  },
  {
    "objectID": "w03/slides.html#the-github-side-remote",
    "href": "w03/slides.html#the-github-side-remote",
    "title": "Week 3: Data Science Workflow",
    "section": "The GitHub Side: Remote",
    "text": "The GitHub Side: Remote"
  },
  {
    "objectID": "w03/slides.html#an-empty-repo",
    "href": "w03/slides.html#an-empty-repo",
    "title": "Week 3: Data Science Workflow",
    "section": "An Empty Repo",
    "text": "An Empty Repo"
  },
  {
    "objectID": "w03/slides.html#refresh-after-git-push",
    "href": "w03/slides.html#refresh-after-git-push",
    "title": "Week 3: Data Science Workflow",
    "section": "Refresh after git push",
    "text": "Refresh after git push"
  },
  {
    "objectID": "w03/slides.html#commit-history",
    "href": "w03/slides.html#commit-history",
    "title": "Week 3: Data Science Workflow",
    "section": "Commit History",
    "text": "Commit History"
  },
  {
    "objectID": "w03/slides.html#checking-the-diff",
    "href": "w03/slides.html#checking-the-diff",
    "title": "Week 3: Data Science Workflow",
    "section": "Checking the diff",
    "text": "Checking the diff"
  },
  {
    "objectID": "w03/slides.html#web-development",
    "href": "w03/slides.html#web-development",
    "title": "Week 3: Data Science Workflow",
    "section": "Web Development",
    "text": "Web Development\n\n\n\n\n\n\n\n\n\nFrontend   \nBackend   \n\n\n\n\nLow Level\nHTML/CSS/JavaScript\nGitHub Pages\n\n\nMiddle Level\nJS Libraries\nPHP, SQL\n\n\nHigh Level\nReact, Next.js\nNode.js, Vercel\n\n\n\n\nFrontend icons: UI+UI elements, what the user sees (on the screen), user experience (UX), data visualization Backend icons: Databases, Security"
  },
  {
    "objectID": "w03/slides.html#getting-content-onto-the-internet",
    "href": "w03/slides.html#getting-content-onto-the-internet",
    "title": "Week 3: Data Science Workflow",
    "section": "Getting Content onto the Internet",
    "text": "Getting Content onto the Internet\n\n\n\n\nStep 1: index.html\n\n\nStep 2: Create GitHub repository\n\n\nStep 3: git init, git add -A ., git push\n\n\nStep 4: Enable GitHub Pages in repo settings\n\n\nStep 5: &lt;username&gt;.github.io!"
  },
  {
    "objectID": "w03/slides.html#deploying-from-a-branchfolder",
    "href": "w03/slides.html#deploying-from-a-branchfolder",
    "title": "Week 3: Data Science Workflow",
    "section": "Deploying from a Branch/Folder",
    "text": "Deploying from a Branch/Folder"
  },
  {
    "objectID": "w03/slides.html#lab-demonstration-1-transferring-files",
    "href": "w03/slides.html#lab-demonstration-1-transferring-files",
    "title": "Week 3: Data Science Workflow",
    "section": "Lab Demonstration 1: Transferring Files",
    "text": "Lab Demonstration 1: Transferring Files"
  },
  {
    "objectID": "w03/slides.html#lab-demonstration-2-quarto",
    "href": "w03/slides.html#lab-demonstration-2-quarto",
    "title": "Week 3: Data Science Workflow",
    "section": "Lab Demonstration 2: Quarto",
    "text": "Lab Demonstration 2: Quarto"
  },
  {
    "objectID": "w03/slides.html#lab-demonstration-3-git-and-github",
    "href": "w03/slides.html#lab-demonstration-3-git-and-github",
    "title": "Week 3: Data Science Workflow",
    "section": "Lab Demonstration 3: Git and GitHub",
    "text": "Lab Demonstration 3: Git and GitHub"
  },
  {
    "objectID": "w03/slides.html#assignment-overview",
    "href": "w03/slides.html#assignment-overview",
    "title": "Week 3: Data Science Workflow",
    "section": "Assignment Overview",
    "text": "Assignment Overview\n\nCreate a repo on your private GitHub account called 5000-lab-1.2\nClone the repo to your local machine with git clone\nCreate a blank Quarto website project, then use a .bib file to add citations\nAdd content to index.qmd\nAdd content to about.ipynb\nBuild a simple presentation in slides/slides.ipynb using the revealjs format\nRender the website using quarto render\nSync your changes to GitHub\nUse rsync or scp to copy the _site directory to your GU domains server (within ~/public_html)\nCreate a Zotero (or Mendeley) account, download the software, and add at least one reference to your site by syncing the .bib file"
  },
  {
    "objectID": "w03/slides.html#references",
    "href": "w03/slides.html#references",
    "title": "Week 3: Data Science Workflow",
    "section": "References",
    "text": "References\n\n\nBaker, Monya. 2016. “1,500 Scientists Lift the Lid on Reproducibility.” Nature 533 (7604): 452–54. https://doi.org/10.1038/533452a.\n\n\nMenczer, Filippo, Santo Fortunato, and Clayton A. Davis. 2020. A First Course in Network Science. Cambridge University Press."
  },
  {
    "objectID": "w04/github-auth.html",
    "href": "w04/github-auth.html",
    "title": "",
    "section": "",
    "text": "import github\ng = github.Github()\ntry:\n    g.get_repo(\"jpowerj/private-repo-test\")\nexcept Exception as e:\n    print(e)\n\n404 {\"message\": \"Not Found\", \"documentation_url\": \"https://docs.github.com/rest/repos/repos#get-a-repository\"}\n\n\n\n# Load the access token securely\nimport dotenv\ndotenv.load_dotenv(\"../.env\", override=True)\nimport os\nmy_access_token = os.getenv('GITHUB_TOKEN')\nimport github\n# Use the access token to make an API request\nauth = github.Auth.Token(my_access_token)\ng = github.Github(auth=auth)\ng.get_user().get_repo(\"private-repo-test\")\n\nRepository(full_name=\"jpowerj/private-repo-test\")"
  },
  {
    "objectID": "recordings/index.html",
    "href": "recordings/index.html",
    "title": "Lecture Recordings / Extra Videos",
    "section": "",
    "text": "Order By\n       Default\n         \n          Week\n        \n         \n          Section\n        \n         \n          Title\n        \n         \n          Last Updated - Oldest\n        \n         \n          Last Updated - Newest\n        \n         \n          Category\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\nWeek\n\n\nTitle\n\n\nSection\n\n\nCategory\n\n\nLast Updated\n\n\n\n\n\n\n4\n\n\nWeek 04: Lecture+Lab (Sec 02)\n\n\n02\n\n\nLecture Recordings\n\n\nTuesday Sep 12, 2023\n\n\n\n\n4\n\n\nWeek 04: Lecture (Sec 03)\n\n\n03\n\n\nLecture Recordings\n\n\nWednesday Sep 13, 2023\n\n\n\n\n4\n\n\nWeek 04: Lab (Sec 03)\n\n\n03\n\n\nLecture Recordings\n\n\nWednesday Sep 13, 2023\n\n\n\n\n3\n\n\nSetting Up VSCode with Quarto\n\n\n\n\n\nExtra Videos\n\n\nThursday Sep 14, 2023\n\n\n\n\n3\n\n\nW03 Lecture+Lab (Sec 02 and 03)\n\n\n\n\n\nLecture Recordings\n\n\nTuesday Sep 5, 2023\n\n\n\n\n3\n\n\nGit and GitHub\n\n\n\n\n\nExtra Videos\n\n\nWednesday Sep 13, 2023\n\n\n\n\n3\n\n\nSSH and SCP on Georgetown Domains\n\n\n\n\n\nExtra Videos\n\n\nThursday Sep 14, 2023\n\n\n\n\n3\n\n\nQuarto Websites\n\n\n\n\n\nExtra Videos\n\n\nThursday Sep 14, 2023\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "writeups/hw1-clarifications/index.html",
    "href": "writeups/hw1-clarifications/index.html",
    "title": "Homework 1 Clarifications",
    "section": "",
    "text": "Relevant Links\n\n\n\n\nMain Course Page:\n\nHomework 1 Assignment Page\nProject Topic Spreadsheet (Claim your project topic here! See Step 4 on the assignment page)\n\nOther Writeups:\n\nUsing Quarto’s Reference/Citation Manager"
  },
  {
    "objectID": "writeups/hw1-clarifications/index.html#due-date-clarification-pushed-to-sep-21",
    "href": "writeups/hw1-clarifications/index.html#due-date-clarification-pushed-to-sep-21",
    "title": "Homework 1 Clarifications",
    "section": "⚠️ Due Date Clarification: Pushed to Sep 21",
    "text": "⚠️ Due Date Clarification: Pushed to Sep 21\n\nImportant clarification for Jeff’s DSAN 5000 sections (02 and 03): Because of my delay in teaching you all the lab material, I am pushing the due date for Homework 1, for both Section 02 and Section 03, forward to Thursday, September 21st at 11:59pm EDT."
  },
  {
    "objectID": "writeups/hw1-clarifications/index.html#hw1-step-2-cloning-the-github-repo",
    "href": "writeups/hw1-clarifications/index.html#hw1-step-2-cloning-the-github-repo",
    "title": "Homework 1 Clarifications",
    "section": "(HW1 Step 2) Cloning the GitHub repo",
    "text": "(HW1 Step 2) Cloning the GitHub repo\n\nThe GitHub repository that is automatically created when you accept the GitHub Classroom assignment defaults to private. This may be an issue if you have not yet set up a Personal Access Token on your GitHub account, or if you have run into issues when trying to set up the Personal Access Token. See this page for GitHub’s documentation on how to set up and manage these tokens.\n\nOnce you have created a token, run the following command:\n\ngit clone https://github.com/anly501/dsan-5000-project-[your username].git\n\nThis command tells git that you’d like it to clone (i.e., copy) the automatically-created dsan-5000-project-[your username] repository to your local computer.\nBut, it may ask you for a password before it allows this downloading. If so, do not enter your “main” GitHub password: GitHub is phasing out the ability to use this password to clone repositories. Instead, just copy-and-paste the Personal Access Token you created into the terminal (as in, paste this Token instead of typing out your GitHub account password).\nIt should now download the remote (automatically-created) repository to your local drive. (If it doesn’t, or if you’re still experiencing issues, feel free to email me or sign up for an office hours slot!)"
  },
  {
    "objectID": "writeups/index.html",
    "href": "writeups/index.html",
    "title": "Extra Writeups",
    "section": "",
    "text": "Order By\n       Default\n         \n          Last Updated - Oldest\n        \n         \n          Last Updated - Newest\n        \n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\nTitle\n\n\nLast Updated\n\n\nCategory\n\n\n\n\n\n\nUsing Quarto’s Reference Manager with Zotero\n\n\nFriday Sep 15, 2023, 02:51:05\n\n\nExtra Writeups\n\n\n\n\nLab 1.2 Clarifications\n\n\nFriday Sep 15, 2023, 00:32:12\n\n\nClarifications\n\n\n\n\nTroubleshooting SSH/SCP/rsync on Georgetown Domains\n\n\nThursday Sep 14, 2023, 23:16:44\n\n\nExtra Writeups\n\n\n\n\nMaking Multiple Columns\n\n\nThursday Sep 14, 2023, 18:07:24\n\n\nExtra Writeups\n\n\n\n\nHomework 1 Clarifications\n\n\nWednesday Sep 13, 2023, 01:57:22\n\n\nClarifications\n\n\n\n\nUsing Quarto’s Reference Manager with Google Scholar\n\n\nWednesday Sep 13, 2023, 01:57:22\n\n\nExtra Writeups\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "writeups/refs-and-citations/index.html",
    "href": "writeups/refs-and-citations/index.html",
    "title": "Using Quarto’s Reference Manager with Google Scholar",
    "section": "",
    "text": "For your homework and your project, we ask you to integrate references into your Quarto documents, a process which invovles the following steps:\nThis walkthrough will show you the details of each step.\nFirst things first, there are many ways to obtain references, and many formats that the references can come in, but the format used by Quarto is called BibTeX. Long story short, there are two ways to obtain BibTeX-style reference info for a given paper or book. The first way (using Google Scholar) is simple, and will let you immediately generate a references.bib file. The second way (using a reference manager like Zotero or Mendeley) takes a bit longer to get set up, but will save you SO much time in the long run. In this writeup we’ll use the Google Scholar approach, but I highly recommend reading the writeup on using Zotero to learn the Zotero/Mendeley approach as well."
  },
  {
    "objectID": "writeups/refs-and-citations/index.html#step-1-obtaining-references-and-creating-a-.bib-file",
    "href": "writeups/refs-and-citations/index.html#step-1-obtaining-references-and-creating-a-.bib-file",
    "title": "Using Quarto’s Reference Manager with Google Scholar",
    "section": "Step 1: Obtaining References and Creating a .bib File",
    "text": "Step 1: Obtaining References and Creating a .bib File\n\nStep 1.1: Obtaining Your First Reference\nAn easy way to quickly obtain references in a format where you can immediately cite them in your Quarto documents is to use Google Scholar. If you open that link, and search for a topic you’re interested in, it should show you a big list of results that looks like:\n\n\n\nFigure 1: Results from searching for “Einstein” on Google Scholar\n\n\nNow, if you choose one of these references and click the “Cite” button at the bottom of the result, it should display a popup (modal) dialog that looks like the following:\n\n\n\nFigure 2: The popup (modal) dialog which comes up if you click the “Cite” link at the bottom of the Google Scholar result\n\n\nNow, if you click on the “BibTeX” link, the first link at the bottom of this popup (modal) window, it should immediately open a new tab containing a plaintext version of the BibTeX data for this reference, like:\n\n\n\nThe BibTeX data for the selected reference, obtained by clicking the “BibTeX” link at the bottom of the “Cite” popup\n\n\n\n\n\n\n\n\nIf you don’t see this plaintext data, that probably means that your browser is set to download rather than just display .bib files, so just look in your Downloads folder for the downloaded file (it might have some weird name, and it might not have a .bib extension, but that’s ok, it will still open in a text editor like VSCode), open it in a text editor, and it should contain exactly the above data.\n\n\n\nHowever you end up with this plaintext reference data, copy and paste it into a new text file (in VSCode, you can create a new plaintext file using Cmd+N), and save this file as references.bib.\nThat’s it! You now have a fully-fledged references.bib file, that looks as follows:\n\n\nreferences.bib\n\n@book{barnett2005universe,\n  title={The Universe and Dr. Einstein},\n  author={Barnett, Lincoln and Einstein, Albert},\n  year={2005},\n  publisher={Courier Corporation}\n}\n\n\n\nStep 1.2: Adding Additional References\nOur references.bib file only contains one reference at the moment, but we can quickly add more by repeating the above process: find another reference you’d like to cite, click the “Cite” link underneath that reference, click the “BibTeX” link at the bottom of the “Cite” dialog box, and copy the resulting (plaintext) data into your references.bib file. Make sure to separate each reference within the .bib file by at least one space, so that for example it may look like the following:\n\n\nreferences.bib\n\n@book{barnett2005universe,\n  title={The Universe and Dr. Einstein},\n  author={Barnett, Lincoln and Einstein, Albert},\n  year={2005},\n  publisher={Courier Corporation}\n}\n\n@book{einstein2017einstein,\n  title={Einstein on peace},\n  author={Einstein, Albert},\n  year={2017},\n  publisher={Pickle Partners Publishing}\n}"
  },
  {
    "objectID": "writeups/refs-and-citations/index.html#step-2-citing-the-references.bib-file-from-within-quarto",
    "href": "writeups/refs-and-citations/index.html#step-2-citing-the-references.bib-file-from-within-quarto",
    "title": "Using Quarto’s Reference Manager with Google Scholar",
    "section": "Step 2: Citing the references.bib File From Within Quarto",
    "text": "Step 2: Citing the references.bib File From Within Quarto\nNow that you’ve created your references.bib file, and filled it with two references, we need to carry out two final steps if we want to cite references from this file when creating content in a .qmd file.\n\nStep 2.1: Telling Quarto About Your .bib File\nLet’s say you are modifying a file called introduction.qmd, and in this file you’d like to cite one or more of the references contained in references.bib. Hopefully it’s becoming a bit of a habit now, that if we want to give Quarto some information to use when it goes to render the .qmd, we need to include this information within the metadata block at the top of the page. So, if you are editing introduction.qmd, and its metadata block currently looks like\n---\ntitle: \"Introduction\"\nauthor: \"DSAN 5000 Student\"\n---\nYou’ll need to add an additional line to this metadata block telling Quarto where it can find the .bib file—that is, you’ll need to give it a relative path telling it how to get from the introduction.qmd file to the references.bib file. The syntax for this metadata entry looks like bibliography: &lt;path-to-file&gt;. So, if our references.bib file happened to be in the same exact folder as the introduction.qmd file, we could simply add\nbibliography: references.bib\nto the metadata block. Or, if you placed the references.bib file in a subdirectory of the directory containing introduction.qmd (say, a subdirectory called assets), you would need to tell Quarto to look for the .bib file within this subdirectory:\nbibliography: assets/references.bib\nIf the .bib file instead was placed one level above the location of the introduction.qmd file in your directory tree, then the following would tell Quarto to look there:\nbibliography: ../references.bib\nOnce you have pointed Quarto to the location of your references.bib file, all that’s left is to actually cite one or more of the references within the content of introduction.qmd.\n\n\nStep 2.2: Citing references.bib Entries Within a Quarto Document\nFor this final step, recall what the contents of the .bib file you created look like:\n\n\nreferences.bib\n\n@book{barnett2005universe,\n  title={The Universe and Dr. Einstein},\n  author={Barnett, Lincoln and Einstein, Albert},\n  year={2005},\n  publisher={Courier Corporation}\n}\n\n@book{einstein2017einstein,\n  title={Einstein on peace},\n  author={Einstein, Albert},\n  year={2017},\n  publisher={Pickle Partners Publishing}\n}\n\nFrom this structure, we can see that @book tells Quarto that this entry is a book (this could, alternatively, be @article or @conference-proceedings, for example), and then after the line containing this entry type information we see key-value pairs containing the relevant information: the title, author, year and publisher of each book.\nThe key thing to notice in our case, however, is the “code” which is given immediately after the entry type: barnett2005universe and einstein2017einstein. These are called citation keys, and they are what we use to refer to entries in our .bib file from within our .qmd documents!\nSo, for example, if we started writing the content of our introduction.qmd page before we created the references.bib file, it may have looked like:\n\n\n\n\n\n\nintroduction.qmd Before Setting Up References\n\n\n\nIn this project we are studying the life and work of Albert Einstein. Barnett (2005) is a key work about Einstein's scientific contributions, while Einstein (2017) contains a collection of Einstein's writings on peace in the years before and after World War II.\n\n\nThe issue is: If we kept it like this and started writing dozens and dozens of paragraphs, but our boss came along and said “Hey! We need you to switch to a different citation format!”, you would have to go back through your document and manually update each in-text citation to match the new format, plus you would need to (a) manually create a “References” section at the end, and (b) manually update it if your boss requests a change in how the end-of-article references should be formatted.\nSo, instead, we use the citation keys mentioned above (which should be present for each entry in your references.bib file) to indicate to Quarto when we’d like to cite something, and Quarto will handle the rest! If your boss comes along and requests a change, you no longer need to manually update each citation/reference: Quarto allows you to specify formatting as a set of global options, which it then automatically applies to each citation and reference. For example, to utilize this system, we can now update our introduction.qmd file to look as follows:\n\n\n\n\n\n\nintroduction.qmd After Setting Up References\n\n\n\nIn this project we are studying the life and work of Albert Einstein. @barnett2005universe is a key work about Einstein's scientific contributions, while @einstein2017einstein contains a collection of Einstein's writings on peace in the years before and after World War II.\n\n\nAnd when Quarto goes to render this introduction.qmd file (for example, after you run quarto render in the root folder containing your website files), it will see these citation keys indicated by the @ symbol followed by the key from the references.bib file, and style the citation by filling in all of the relevant information for this item from references.bib. To see the difference, the following two blocks show the rendered version of this paragraph without and then with Quarto’s reference-management features set up:\n\n\n\n\n\n\nRendered introduction.qmd Content Without Citation Keys\n\n\n\nIn this project we are studying the life and work of Albert Einstein. Barnett and Einstein (2005) is a key work about Einstein’s scientific contributions, while Einstein (2017) contains a collection of Einstein’s writings on peace in the years before and after World War II.\n\n\n\n\n\n\n\n\nRendered introduction.qmd Content With Citation Keys\n\n\n\nIn this project we are studying the life and work of Albert Einstein. Barnett and Einstein (2005) is a key work about Einstein’s scientific contributions, while Einstein (2017) contains a collection of Einstein’s writings on peace in the years before and after World War II.\n\n\nNotice how, in the rendered version with citation keys:\n\nThe parenthesized year in each citation is now colored blue, and when you hover your mouse over these years it should show a popup containing more information about the cited book.\nQuarto also auto-generated a “References” section for our article, which you should see at the bottom of this page."
  },
  {
    "objectID": "about/slides.html#prof.-jeff-introduction",
    "href": "about/slides.html#prof.-jeff-introduction",
    "title": "About Me",
    "section": "Prof. Jeff Introduction!",
    "text": "Prof. Jeff Introduction!\n\nBorn and raised in NW DC → high school in Rockville, MD\nUniversity of Maryland: Computer Science, Math, Economics (2008-2012)"
  },
  {
    "objectID": "about/slides.html#grad-school",
    "href": "about/slides.html#grad-school",
    "title": "About Me",
    "section": "Grad School",
    "text": "Grad School\n\nStudied abroad in Beijing (Peking University/北大) → internship with Huawei in Hong Kong (HKUST)\n\n\n\n\nStanford for MS in Computer Science (2012-2014)\nResearch Economist at UC Berkeley (2014-2015)\n\n\n\n\n\n\nColumbia (NYC) for PhD[+Postdoc] in Political Science (2015-2023)"
  },
  {
    "objectID": "about/slides.html#dissertation-political-science-history",
    "href": "about/slides.html#dissertation-political-science-history",
    "title": "About Me",
    "section": "Dissertation (Political Science + History)",
    "text": "Dissertation (Political Science + History)\n“Our Word is Our Weapon”: Text-Analyzing Wars of Ideas from the French Revolution to the First Intifada"
  },
  {
    "objectID": "about/slides.html#research-labor-economics",
    "href": "about/slides.html#research-labor-economics",
    "title": "About Me",
    "section": "Research (Labor Economics)",
    "text": "Research (Labor Economics)\n\n\n\n“Monopsony in Online Labor Markets”: Machine Learning to enhance causal estimates of the effect of job description language on uptake rate\n\n\n\n“Freedom as Non-Domination in the Labor Market”: Game-theoretic models of workers’ rights (monopsony vs. labor discipline)\n\n\n\n\n\n“Unsupervised Extraction of Workplace Rights and Duties from Collective Bargaining Agreements”: Linguistic (dependency) parses of contracts → time series of worker vs. employer rights and responsibilities over time"
  },
  {
    "objectID": "about/index.html",
    "href": "about/index.html",
    "title": "About Me",
    "section": "",
    "text": "Born and raised in NW DC → high school in Rockville, MD\nUniversity of Maryland: Computer Science, Math, Economics (2008-2012)"
  },
  {
    "objectID": "about/index.html#prof.-jeff-introduction",
    "href": "about/index.html#prof.-jeff-introduction",
    "title": "About Me",
    "section": "",
    "text": "Born and raised in NW DC → high school in Rockville, MD\nUniversity of Maryland: Computer Science, Math, Economics (2008-2012)"
  },
  {
    "objectID": "about/index.html#grad-school",
    "href": "about/index.html#grad-school",
    "title": "About Me",
    "section": "Grad School",
    "text": "Grad School\n\nStudied abroad in Beijing (Peking University/北大) → internship with Huawei in Hong Kong (HKUST)\n\n\n\n\nStanford for MS in Computer Science (2012-2014)\nResearch Economist at UC Berkeley (2014-2015)\n\n\n\n\n\n\nColumbia (NYC) for PhD[+Postdoc] in Political Science (2015-2023)"
  },
  {
    "objectID": "about/index.html#dissertation-political-science-history",
    "href": "about/index.html#dissertation-political-science-history",
    "title": "About Me",
    "section": "Dissertation (Political Science + History)",
    "text": "Dissertation (Political Science + History)\n“Our Word is Our Weapon”: Text-Analyzing Wars of Ideas from the French Revolution to the First Intifada"
  },
  {
    "objectID": "about/index.html#research-labor-economics",
    "href": "about/index.html#research-labor-economics",
    "title": "About Me",
    "section": "Research (Labor Economics)",
    "text": "Research (Labor Economics)\n\n\n\n“Monopsony in Online Labor Markets”: Machine Learning to enhance causal estimates of the effect of job description language on uptake rate\n\n\n\n“Freedom as Non-Domination in the Labor Market”: Game-theoretic models of workers’ rights (monopsony vs. labor discipline)\n\n\n\n\n\n“Unsupervised Extraction of Workplace Rights and Duties from Collective Bargaining Agreements”: Linguistic (dependency) parses of contracts → time series of worker vs. employer rights and responsibilities over time"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Extra Writeups",
    "section": "",
    "text": "Order By\n       Default\n         \n          Last Updated - Oldest\n        \n         \n          Last Updated - Newest\n        \n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\nTitle\n\n\nLast Updated\n\n\nCategory\n\n\n\n\n\n\nUsing Quarto’s Reference Manager with Zotero\n\n\nFriday Sep 15, 2023, 02:51:05\n\n\nExtra Writeups\n\n\n\n\nLab 1.2 Clarifications\n\n\nFriday Sep 15, 2023, 00:32:12\n\n\nClarifications\n\n\n\n\nTroubleshooting SSH/SCP/rsync on Georgetown Domains\n\n\nThursday Sep 14, 2023, 23:16:44\n\n\nExtra Writeups\n\n\n\n\nMaking Multiple Columns\n\n\nThursday Sep 14, 2023, 18:07:24\n\n\nExtra Writeups\n\n\n\n\nHomework 1 Clarifications\n\n\nWednesday Sep 13, 2023, 01:57:22\n\n\nClarifications\n\n\n\n\nUsing Quarto’s Reference Manager with Google Scholar\n\n\nWednesday Sep 13, 2023, 01:57:22\n\n\nExtra Writeups\n\n\n\n\n\n\nNo matching items"
  }
]